{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4ba61c-cefe-4e24-b31d-dc18d8373df9",
   "metadata": {},
   "source": [
    "## Game environment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0fba5593-2958-4ebf-ba29-db14c4960467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Environment Utilities Loaded.\n"
     ]
    }
   ],
   "source": [
    "#Game Environment Utilities\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# --- Constants ---\n",
    "ROWS = 6\n",
    "COLS = 7\n",
    "EMPTY = 0\n",
    "PLAYER1_PIECE = 1\n",
    "PLAYER2_PIECE = 2\n",
    "\n",
    "# --- Board Functions ---\n",
    "def create_board():\n",
    "    \"\"\"Creates an empty Connect 4 board.\"\"\"\n",
    "    return np.zeros((ROWS, COLS), dtype=int)\n",
    "\n",
    "def print_board(board):\n",
    "    \"\"\"Prints the board to the console in a formatted way.\"\"\"\n",
    "    # Map internal values to display characters\n",
    "    piece_map = {\n",
    "        EMPTY: \" \",\n",
    "        PLAYER1_PIECE: \"X\", # Player 1\n",
    "        PLAYER2_PIECE: \"O\"  # Player 2 (Using 'O' instead of '0' for clarity)\n",
    "    }\n",
    "\n",
    "    # Print the board rows from top to bottom (needs flipping)\n",
    "    flipped_board = np.flip(board, 0)\n",
    "    for r in range(ROWS):\n",
    "        row_str = \"| \" # Start of the row border\n",
    "        # Join pieces with spaces in between\n",
    "        row_str += \" \".join([piece_map[flipped_board[r][c]] for c in range(COLS)])\n",
    "        row_str += \" |\" # End of the row border\n",
    "        print(row_str)\n",
    "\n",
    "    # Print the bottom border\n",
    "    print(\"+\" + \"-\" * (COLS * 2 + 1) + \"+\") # Adjust width based on spacing\n",
    "\n",
    "    # Print the column numbers (1-7) aligned below\n",
    "    col_numbers = \"  \" + \" \".join(map(str, range(1, COLS + 1)))\n",
    "    print(col_numbers)\n",
    "\n",
    "def is_valid_location(board, col):\n",
    "    \"\"\"Checks if a column is valid for dropping a piece.\"\"\"\n",
    "    return 0 <= col < COLS and board[ROWS - 1][col] == EMPTY \n",
    "\n",
    "def get_next_open_row(board, col):\n",
    "    \"\"\"Finds the lowest empty row in a given column.\"\"\"\n",
    "    for r in range(ROWS):\n",
    "        if board[r][col] == EMPTY:\n",
    "            return r\n",
    "    return None \n",
    "\n",
    "def drop_piece(board, row, col, piece):\n",
    "    \"\"\"Places a piece on the board at the specified location.\"\"\"\n",
    "    board[row][col] = piece\n",
    "\n",
    "def get_valid_locations(board):\n",
    "    \"\"\"Returns a list of columns where a piece can be dropped.\"\"\"\n",
    "    return [col for col in range(COLS) if is_valid_location(board, col)]\n",
    "\n",
    "# --- Winning Condition Logic ---\n",
    "def winning_move(board, piece):\n",
    "    \"\"\"Checks if the specified player has won.\"\"\"\n",
    "    # Check horizontal locations\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(ROWS):\n",
    "            if all(board[r][c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    # Check vertical locations\n",
    "    for c in range(COLS):\n",
    "        for r in range(ROWS - 3):\n",
    "            if all(board[r+i][c] == piece for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    # Check positively sloped diagonals\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(ROWS - 3):\n",
    "            if all(board[r+i][c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    # Check negatively sloped diagonals\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(3, ROWS):\n",
    "            if all(board[r-i][c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def is_terminal_node(board):\n",
    "    \"\"\"Checks if the game has ended (win or draw).\"\"\"\n",
    "    return winning_move(board, PLAYER1_PIECE) or \\\n",
    "           winning_move(board, PLAYER2_PIECE) or \\\n",
    "           len(get_valid_locations(board)) == 0\n",
    "\n",
    "print(\"Game Environment Utilities Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c0448-fc1c-4d46-b07a-4c7ea5ed852d",
   "metadata": {},
   "source": [
    "## Player Base Class & Human Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6bc50cce-93a0-4ef7-bc12-2aa42904136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player Base Class and HumanPlayer Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Player Base Class & Human Player\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Player(ABC):\n",
    "    \"\"\"Abstract base class for all Connect 4 players.\"\"\"\n",
    "    def __init__(self, player_id):\n",
    "        self.player_id = player_id \n",
    "\n",
    "    @abstractmethod\n",
    "    def get_move(self, board):\n",
    "        \"\"\"\n",
    "        Given the current board state, returns the column where the player wants to move.\n",
    "\n",
    "        Args:\n",
    "            board (np.ndarray): The current 6x7 game board.\n",
    "\n",
    "        Returns:\n",
    "            int: The column index (0-6) for the move.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class HumanPlayer(Player):\n",
    "    \"\"\"A player controlled by human input via the console (accepts 1-7).\"\"\"\n",
    "    def get_move(self, board):\n",
    "        \"\"\"Gets move from user input, expecting 1-7.\"\"\"\n",
    "        valid_locations_zero_based = get_valid_locations(board) # Gets 0-6\n",
    "\n",
    "        # Convert valid locations to 1-7 for display\n",
    "        valid_locations_display = [loc + 1 for loc in valid_locations_zero_based]\n",
    "\n",
    "        if not valid_locations_display:\n",
    "             print(\"Error: No valid moves available!\")\n",
    "             return None # Or handle this scenario as appropriate\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Ask for input in the 1-7 range\n",
    "                col_str = input(f\"Player {self.player_id}, choose column ({', '.join(map(str, valid_locations_display))}): \")\n",
    "                user_col = int(col_str) # User inputs 1-7\n",
    "\n",
    "                # Convert user input (1-7) back to zero-based index (0-6) for internal use\n",
    "                internal_col = user_col - 1\n",
    "\n",
    "                # Validate using the zero-based index\n",
    "                if internal_col in valid_locations_zero_based:\n",
    "                    return internal_col # Return the 0-6 index\n",
    "                else:\n",
    "                    print(f\"Invalid column {user_col}. Please choose from {valid_locations_display}.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a number.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "print(\"Player Base Class and HumanPlayer Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefa0f6-5f1e-491f-a08b-287d1b4b3766",
   "metadata": {},
   "source": [
    "## CNN Model Training & Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c7a2f9-0112-4f70-905f-0d6b8cbc899b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Original unique y values: [-1.  0.  1.]\n",
      "Mapped unique y values: [0. 1. 2.]\n",
      "Shape of X: (376619, 6, 7)\n",
      "Shape of y: (376619,)\n",
      "X_train_cnn shape: (301295, 6, 7, 1)\n",
      "y_train shape: (301295,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrgu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,523</span> (107.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,523\u001b[0m (107.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,523</span> (107.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,523\u001b[0m (107.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training CNN Model ---\n",
      "Epoch 1/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.3846 - val_accuracy: 0.9284 - val_loss: 0.1767\n",
      "Epoch 2/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.1852 - val_accuracy: 0.9480 - val_loss: 0.1333\n",
      "Epoch 3/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.1380 - val_accuracy: 0.9570 - val_loss: 0.1111\n",
      "Epoch 4/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.1131 - val_accuracy: 0.9656 - val_loss: 0.0901\n",
      "Epoch 5/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.0985 - val_accuracy: 0.9672 - val_loss: 0.0872\n",
      "Epoch 6/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.0844 - val_accuracy: 0.9711 - val_loss: 0.0756\n",
      "Epoch 7/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0733 - val_accuracy: 0.9705 - val_loss: 0.0764\n",
      "Epoch 8/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0671 - val_accuracy: 0.9746 - val_loss: 0.0671\n",
      "Epoch 9/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0605 - val_accuracy: 0.9770 - val_loss: 0.0608\n",
      "Epoch 10/10\n",
      "\u001b[1m9416/9416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0572 - val_accuracy: 0.9784 - val_loss: 0.0590\n",
      "\n",
      "--- Evaluating CNN Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0590\n",
      "Test Accuracy: 0.9784\n",
      "\n",
      "CNN Model saved to connect4_cnn_model.h5\n"
     ]
    }
   ],
   "source": [
    "# CNN Model Training & Saving\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# --- Data Loading and Preparation ---\n",
    "try:\n",
    "    df = pd.read_csv(\"c4_game_database.csv\") # Data from Kaggle\n",
    "    df = df.rename(columns={'42': 'winner'})\n",
    "    df = df.dropna(subset=['winner'])\n",
    "\n",
    "    X = df.iloc[:, :42].values\n",
    "    y = df['winner'].values\n",
    "\n",
    "    # Reshape features to 6x7 boards\n",
    "    # Replace -1 with 2 for Player 2 pieces\n",
    "    X[X == -1] = PLAYER2_PIECE\n",
    "    X = X.reshape(-1, ROWS, COLS)\n",
    "\n",
    "    # Target variable: Assuming winner is 1 (Player 1), -1 (Player 2), 0 (Draw) in CSV\n",
    "    # Check unique values in y to confirm mapping\n",
    "    print(\"Original unique y values:\", np.unique(y))\n",
    "    y_mapped = np.copy(y)\n",
    "    y_mapped[y == 1] = 1  # Player 1 Win remains 1\n",
    "    y_mapped[y == -1] = 2 # Player 2 Win becomes 2\n",
    "    y_mapped[y == 0] = 0  # Draw remains 0 \n",
    "    print(\"Mapped unique y values:\", np.unique(y_mapped))\n",
    "    y = y_mapped\n",
    "\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    # Data Splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) \n",
    "\n",
    "    # Reshape for CNN (add channel dimension)\n",
    "    X_train_cnn = X_train.reshape(-1, ROWS, COLS, 1)\n",
    "    X_test_cnn = X_test.reshape(-1, ROWS, COLS, 1)\n",
    "\n",
    "    print(\"X_train_cnn shape:\", X_train_cnn.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "    # --- CNN Model Definition ---\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='SAME', input_shape=(ROWS, COLS, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='SAME'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    cnn_model.summary()\n",
    "\n",
    "    # --- Model Training ---\n",
    "    print(\"\\n--- Training CNN Model ---\")\n",
    "\n",
    "    history = cnn_model.fit(X_train_cnn, y_train,\n",
    "                            epochs=10, # Adjust epochs as needed\n",
    "                            batch_size=32,\n",
    "                            validation_data=(X_test_cnn, y_test))\n",
    "\n",
    "    print(\"\\n--- Evaluating CNN Model ---\")\n",
    "    loss, accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # --- SAVING THE MODEL ---\n",
    "    model_save_path = 'connect4_cnn_model.h5' # Keras H5 format\n",
    "    cnn_model.save(model_save_path)\n",
    "    print(f\"\\nCNN Model saved to {model_save_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: c4_game_database.csv not found. Cannot train CNN model.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during CNN training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c6275-679e-4887-9f20-25481b655b55",
   "metadata": {},
   "source": [
    "## AI Player - CNN-Minimax Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e8078e33-c8f7-4978-904c-41b225fbc8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNMinimaxPlayer Loaded.\n"
     ]
    }
   ],
   "source": [
    "# CNN-Minimax AI Player Implementation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# --- AI Player using CNN and Minimax ---\n",
    "class CNNMinimaxPlayer(Player):\n",
    "    def __init__(self, player_id, model_path='connect4_cnn_model.h5', search_depth=4):\n",
    "        \"\"\"\n",
    "        Initializes the AI player.\n",
    "\n",
    "        Args:\n",
    "            player_id (int): PLAYER1_PIECE or PLAYER2_PIECE.\n",
    "            model_path (str): Path to the saved Keras model file.\n",
    "            search_depth (int): The depth for the Minimax search.\n",
    "        \"\"\"\n",
    "        super().__init__(player_id)\n",
    "        self.opponent_id = PLAYER1_PIECE if player_id == PLAYER2_PIECE else PLAYER2_PIECE\n",
    "        self.search_depth = search_depth\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(model_path)\n",
    "            print(f\"CNN Model loaded successfully from {model_path} for Player {player_id}\")\n",
    "            # Perform a dummy prediction to ensure the model is fully loaded/compiled\n",
    "            dummy_board = create_board().reshape(1, ROWS, COLS, 1)\n",
    "            _ = self.model.predict(dummy_board, verbose=0)\n",
    "            print(\"Model ready.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model from {model_path}: {e}\")\n",
    "            print(\"CNNMinimaxPlayer will not function correctly.\")\n",
    "            self.model = None\n",
    "\n",
    "    def _evaluate_board_cnn(self, board):\n",
    "        \"\"\"\n",
    "        Evaluates the board state using the CNN model.\n",
    "        Returns a score from Player 1's perspective (higher is better for P1).\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            return 0 # Cannot evaluate without a model\n",
    "\n",
    "        # Reshape board for CNN input\n",
    "        board_cnn = board.reshape(1, ROWS, COLS, 1)\n",
    "        probabilities = self.model.predict(board_cnn, verbose=0)[0]\n",
    "\n",
    "        # probabilities[0] = Draw, probabilities[1] = P1 Win, probabilities[2] = P2 Win\n",
    "        # Score: P1 win probability - P2 win probability\n",
    "        score = probabilities[1] - probabilities[2]\n",
    "        return score\n",
    "\n",
    "    def _minimax(self, board, depth, maximizing_player, alpha, beta):\n",
    "        \"\"\"\n",
    "        Minimax algorithm with Alpha-Beta pruning.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (column, score) - Score is from Player 1's perspective.\n",
    "        \"\"\"\n",
    "        valid_locations = get_valid_locations(board)\n",
    "        is_terminal = is_terminal_node(board)\n",
    "\n",
    "        if depth == 0 or is_terminal:\n",
    "            if is_terminal:\n",
    "                if winning_move(board, PLAYER1_PIECE):\n",
    "                    return (None, 1000000 + depth) # Prioritize faster wins\n",
    "                elif winning_move(board, PLAYER2_PIECE):\n",
    "                    return (None, -1000000 - depth) # Prioritize blocking faster losses\n",
    "                else: # Game is draw\n",
    "                    return (None, 0)\n",
    "            else: # Depth is zero, use CNN evaluation\n",
    "                return (None, self._evaluate_board_cnn(board))\n",
    "\n",
    "        if maximizing_player: # Player 1's turn (Maximize score)\n",
    "            value = -math.inf\n",
    "            best_col = random.choice(valid_locations) # Default move\n",
    "            for col in valid_locations:\n",
    "                row = get_next_open_row(board, col)\n",
    "                temp_board = board.copy()\n",
    "                drop_piece(temp_board, row, col, PLAYER1_PIECE)\n",
    "                _, new_score = self._minimax(temp_board, depth - 1, False, alpha, beta)\n",
    "                if new_score > value:\n",
    "                    value = new_score\n",
    "                    best_col = col\n",
    "                alpha = max(alpha, value)\n",
    "                if alpha >= beta:\n",
    "                    break # Beta cutoff\n",
    "            return best_col, value\n",
    "        else: # Player 2's turn (Minimize score from P1's perspective)\n",
    "            value = math.inf\n",
    "            best_col = random.choice(valid_locations) # Default move\n",
    "            for col in valid_locations:\n",
    "                row = get_next_open_row(board, col)\n",
    "                temp_board = board.copy()\n",
    "                drop_piece(temp_board, row, col, PLAYER2_PIECE)\n",
    "                _, new_score = self._minimax(temp_board, depth - 1, True, alpha, beta)\n",
    "                if new_score < value:\n",
    "                    value = new_score\n",
    "                    best_col = col\n",
    "                beta = min(beta, value)\n",
    "                if alpha >= beta:\n",
    "                    break # Alpha cutoff\n",
    "            return best_col, value\n",
    "\n",
    "    def get_move(self, board):\n",
    "        \"\"\"\n",
    "        Determines the AI's move using Minimax with the CNN evaluator.\n",
    "        Includes checking for immediate wins and blocking opponent wins.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "             print(\"AI Error: Model not loaded. Choosing random move.\")\n",
    "             return random.choice(get_valid_locations(board))\n",
    "\n",
    "        valid_locations = get_valid_locations(board)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 1. Check for immediate winning move for self\n",
    "        for col in valid_locations:\n",
    "            temp_board = board.copy()\n",
    "            row = get_next_open_row(temp_board, col)\n",
    "            drop_piece(temp_board, row, col, self.player_id)\n",
    "            if winning_move(temp_board, self.player_id):\n",
    "                print(f\"AI Player {self.player_id}: Found winning move in column {col}\")\n",
    "                return col\n",
    "\n",
    "        # 2. Check for immediate winning move for opponent and block it\n",
    "        for col in valid_locations:\n",
    "            temp_board = board.copy()\n",
    "            row = get_next_open_row(temp_board, col)\n",
    "            drop_piece(temp_board, row, col, self.opponent_id)\n",
    "            if winning_move(temp_board, self.opponent_id):\n",
    "                print(f\"AI Player {self.player_id}: Blocking opponent win in column {col}\")\n",
    "                return col\n",
    "\n",
    "        # 3. If no immediate win/block, use Minimax\n",
    "        print(f\"AI Player {self.player_id}: Running Minimax (depth {self.search_depth})...\")\n",
    "        # maximizing_player is True if self.player_id is PLAYER1_PIECE\n",
    "        col, minimax_score = self._minimax(board, self.search_depth, self.player_id == PLAYER1_PIECE, -math.inf, math.inf)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"AI Player {self.player_id}: Chose column {col} (Score: {minimax_score:.2f}, Time: {end_time - start_time:.2f}s)\")\n",
    "\n",
    "        if col is None or col not in valid_locations: # Fallback if minimax fails (shouldn't happen often)\n",
    "             print(f\"AI Warning: Minimax returned invalid move {col}. Choosing random valid move.\")\n",
    "             col = random.choice(valid_locations)\n",
    "\n",
    "        return col\n",
    "\n",
    "print(\"CNNMinimaxPlayer Loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b8ffc-66c7-4922-be45-445307fcb153",
   "metadata": {},
   "source": [
    "## AI Player - Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "42456c06-307a-484a-a83f-41a07fc66732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomAIPlayer Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Example - Random AI Player\n",
    "import random\n",
    "\n",
    "class RandomAIPlayer(Player):\n",
    "    \"\"\"An AI player that chooses a valid move randomly.\"\"\"\n",
    "    def get_move(self, board):\n",
    "        valid_locations = get_valid_locations(board)\n",
    "        move = random.choice(valid_locations)\n",
    "        print(f\"Random AI Player {self.player_id}: Chose column {move}\")\n",
    "        time.sleep(0.5) # Add a small delay to simulate thinking\n",
    "        return move\n",
    "\n",
    "print(\"RandomAIPlayer Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c99690-c220-4557-bd6f-510273543d7c",
   "metadata": {},
   "source": [
    "## AI Player - Slightly Better Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8f6cfdfa-4b1f-4bf5-9984-fcf3a0c5588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SlightlyBetterRandomAIPlayer class Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Slightly Better Random AI Player\n",
    "import random\n",
    "import copy\n",
    "\n",
    "class SlightlyBetterRandomAIPlayer(Player):\n",
    "    \"\"\"\n",
    "    An AI player that makes moves based on the following priority:\n",
    "    1. Play a winning move if available.\n",
    "    2. Block the opponent's winning move if available.\n",
    "    3. Choose a random valid move otherwise.\n",
    "    \"\"\"\n",
    "    def __init__(self, player_id):\n",
    "        \"\"\"\n",
    "        Initializes the player.\n",
    "\n",
    "        Args:\n",
    "            player_id (int): PLAYER1_PIECE or PLAYER2_PIECE.\n",
    "        \"\"\"\n",
    "        super().__init__(player_id)\n",
    "        # Determine the opponent's piece ID\n",
    "        self.opponent_id = PLAYER1_PIECE if player_id == PLAYER2_PIECE else PLAYER2_PIECE\n",
    "        print(f\"SlightlyBetterRandomAIPlayer initialized for Player {self.player_id} (Opponent: {self.opponent_id})\")\n",
    "\n",
    "    def get_move(self, board):\n",
    "        \"\"\"\n",
    "        Determines the move based on win, block, or random choice.\n",
    "\n",
    "        Args:\n",
    "            board (np.ndarray): The current 6x7 game board.\n",
    "\n",
    "        Returns:\n",
    "            int: The column index (0-6) for the move.\n",
    "        \"\"\"\n",
    "        valid_locations = get_valid_locations(board)\n",
    "\n",
    "        # 1. Check for immediate winning move for self\n",
    "        for col in valid_locations:\n",
    "            temp_board = board.copy() # Use a copy to simulate the move\n",
    "            row = get_next_open_row(temp_board, col)\n",
    "            if row is not None: # Ensure the column wasn't full (should be covered by valid_locations)\n",
    "                drop_piece(temp_board, row, col, self.player_id)\n",
    "                if winning_move(temp_board, self.player_id):\n",
    "                    # print(f\"SmarterRandom AI {self.player_id}: Found winning move in column {col}\")\n",
    "                    return col\n",
    "\n",
    "        # 2. Check for immediate winning move for opponent and block it\n",
    "        for col in valid_locations:\n",
    "            temp_board = board.copy() # Use a copy to simulate opponent's move\n",
    "            row = get_next_open_row(temp_board, col)\n",
    "            if row is not None:\n",
    "                drop_piece(temp_board, row, col, self.opponent_id)\n",
    "                if winning_move(temp_board, self.opponent_id):\n",
    "                    # print(f\"SmarterRandom AI {self.player_id}: Blocking opponent win in column {col}\")\n",
    "                    return col\n",
    "\n",
    "        # 3. If no win/block, choose a random valid move\n",
    "        move = random.choice(valid_locations)\n",
    "        # print(f\"SmarterRandom AI {self.player_id}: No win/block found. Choosing random column {move}\")\n",
    "        return move\n",
    "\n",
    "print(\"SlightlyBetterRandomAIPlayer class Loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093526b9-e72c-417d-b12b-f9f99acfacd9",
   "metadata": {},
   "source": [
    "## AI Player - MCTS player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e55ad16b-403d-4940-bba6-8419406caa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTSPlayer class Updated with Heuristic Playouts and Corrected UCT.\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Tree Search (MCTS) AI Player with Heuristic Playout & Corrected UCT\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Assuming functions from Cell 1 and Player class from Cell 2 are loaded\n",
    "# from Cell1 import (create_board, print_board, is_valid_location, get_next_open_row,\n",
    "#                    drop_piece, get_valid_locations, winning_move, is_terminal_node,\n",
    "#                    PLAYER1_PIECE, PLAYER2_PIECE, EMPTY, ROWS, COLS)\n",
    "# from Cell2 import Player\n",
    "\n",
    "# --- Define Positional Heuristic ---\n",
    "POSITIONAL_VALUES_RAW = np.array([\n",
    "    [3, 4, 5, 7, 5, 4, 3],\n",
    "    [4, 6, 8, 10, 8, 6, 4],\n",
    "    [5, 8, 11, 13, 11, 8, 5],\n",
    "    [5, 8, 11, 13, 11, 8, 5],\n",
    "    [4, 6, 8, 10, 8, 6, 4],\n",
    "    [3, 4, 5, 7, 5, 4, 3]\n",
    "])\n",
    "POSITIONAL_VALUES = np.flipud(POSITIONAL_VALUES_RAW)\n",
    "\n",
    "# --- MCTS Node ---\n",
    "class MCTSNode:\n",
    "    \"\"\" Represents a node in the Monte Carlo Search Tree. \"\"\"\n",
    "    def __init__(self, state, parent=None, move=None, player_at_node=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.move = move\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.score = 0 # Score relative to player_at_node (+1 win, -1 loss, 0 draw)\n",
    "        self.untried_moves = get_valid_locations(state)\n",
    "        self.player_at_node = player_at_node # Player whose turn it is AT THIS NODE\n",
    "\n",
    "    # ***** THIS FUNCTION IS UPDATED *****\n",
    "    def uct_select_child(self, exploration_constant=1.414):\n",
    "        \"\"\" Selects a child node using the UCT formula, from the parent's perspective. \"\"\"\n",
    "        children_with_visits = [c for c in self.children if c.visits > 0]\n",
    "\n",
    "        if not self.children:\n",
    "             return None # No children to select\n",
    "\n",
    "        # Ensure parent has visits for log calculation\n",
    "        if self.visits == 0:\n",
    "             return random.choice(self.children) if self.children else None\n",
    "\n",
    "        log_parent_visits = math.log(self.visits)\n",
    "\n",
    "        def uct_score(node):\n",
    "            \"\"\" Calculates the UCT score for a child node from the parent's perspective. \"\"\"\n",
    "            if node.visits == 0:\n",
    "                return float('inf')\n",
    "\n",
    "            # node.score / node.visits is the win rate for the player AT THE CHILD node.\n",
    "            child_player_win_rate = node.score / node.visits\n",
    "\n",
    "            # The parent wants to maximize ITS OWN win rate.\n",
    "            # Since the child player is always the opponent in Connect 4,\n",
    "            # Parent's Win Rate = - (Child Player's Win Rate)\n",
    "            parent_perspective_win_rate = -child_player_win_rate\n",
    "\n",
    "            exploration_term = exploration_constant * math.sqrt(log_parent_visits / node.visits)\n",
    "\n",
    "            return parent_perspective_win_rate + exploration_term\n",
    "\n",
    "        # Select the child with the highest UCT score (best for the parent node)\n",
    "        # Consider all children. Unvisited children will get infinite score and be chosen first.\n",
    "        selected_child = max(self.children, key=uct_score)\n",
    "\n",
    "        return selected_child\n",
    "        \n",
    "\n",
    "    def add_child(self, move, state, player_at_new_node):\n",
    "        \"\"\" Adds a new child node. \"\"\"\n",
    "        node = MCTSNode(state=state, parent=self, move=move, player_at_node=player_at_new_node)\n",
    "        if move in self.untried_moves:\n",
    "             self.untried_moves.remove(move)\n",
    "        self.children.append(node)\n",
    "        return node\n",
    "\n",
    "    def update(self, result_from_perspective_of_player_at_this_node):\n",
    "        \"\"\" Updates visit count and score. \"\"\"\n",
    "        self.visits += 1\n",
    "        self.score += result_from_perspective_of_player_at_this_node\n",
    "\n",
    "\n",
    "# --- MCTS Player ---\n",
    "class MCTSPlayer(Player):\n",
    "    \"\"\" AI player implementing Monte Carlo Tree Search with Heuristic Playouts. \"\"\"\n",
    "    def __init__(self, player_id, iterations=1000, exploration_constant=1.414):\n",
    "        super().__init__(player_id)\n",
    "        self.opponent_id = PLAYER1_PIECE if player_id == PLAYER2_PIECE else PLAYER2_PIECE\n",
    "        self.n_iterations = iterations\n",
    "        self.exploration_constant = exploration_constant\n",
    "        self.positional_values = POSITIONAL_VALUES\n",
    "        print(f\"MCTSPlayer initialized for Player {self.player_id} ({self.n_iterations} iterations/move, Heuristic Playouts, Corrected UCT)\")\n",
    "\n",
    "    def get_move(self, board):\n",
    "        start_time = time.time()\n",
    "        root = MCTSNode(state=board.copy(), player_at_node=self.player_id)\n",
    "\n",
    "        # Check immediate win/loss first (efficient)\n",
    "        valid_locations = get_valid_locations(board)\n",
    "        for col in valid_locations:\n",
    "             temp_board_win = board.copy()\n",
    "             row_win = get_next_open_row(temp_board_win, col)\n",
    "             drop_piece(temp_board_win, row_win, col, self.player_id)\n",
    "             if winning_move(temp_board_win, self.player_id):\n",
    "                 print(f\"MCTS Player {self.player_id}: Found immediate winning move {col}\")\n",
    "                 return col\n",
    "        for col in valid_locations:\n",
    "             temp_board_loss = board.copy()\n",
    "             row_loss = get_next_open_row(temp_board_loss, col)\n",
    "             drop_piece(temp_board_loss, row_loss, col, self.opponent_id)\n",
    "             if winning_move(temp_board_loss, self.opponent_id):\n",
    "                 print(f\"MCTS Player {self.player_id}: Found immediate block at {col}\")\n",
    "                 return col\n",
    "\n",
    "        # MCTS main loop\n",
    "        for i in range(self.n_iterations):\n",
    "            node = root\n",
    "            current_board_state = board.copy()\n",
    "\n",
    "            # 1. Selection\n",
    "            # Node is fully expanded and non-terminal\n",
    "            while not node.untried_moves and node.children:\n",
    "                node = node.uct_select_child(self.exploration_constant)\n",
    "                if node is None: break # Safety check if no children selectable\n",
    "                 # Apply move to descend tree\n",
    "                row = get_next_open_row(current_board_state, node.move)\n",
    "                if row is None: \n",
    "                    print(f\"Warning: Invalid move {node.move} selected during descent.\")\n",
    "                    break\n",
    "                drop_piece(current_board_state, row, node.move, node.parent.player_at_node) # Player at parent made the move\n",
    "\n",
    "            if node is None: continue # Skip iteration if selection failed\n",
    "\n",
    "\n",
    "            # 2. Expansion\n",
    "            # If the selected node is not terminal and has untried moves\n",
    "            if node.untried_moves and not is_terminal_node(node.state): # Check if node state itself is terminal\n",
    "                move = random.choice(node.untried_moves) # Expand randomly among untried\n",
    "                current_player = node.player_at_node\n",
    "                next_player = self.opponent_id if current_player == self.player_id else self.player_id\n",
    "\n",
    "                # Apply the expansion move to the state inherited from selection\n",
    "                row = get_next_open_row(current_board_state, move)\n",
    "                if row is not None:\n",
    "                    drop_piece(current_board_state, row, move, current_player)\n",
    "                    node = node.add_child(move, current_board_state.copy(), next_player) # Add child with the *new* state\n",
    "                else:\n",
    "                    print(f\"Warning: Attempted to expand invalid move {move}. Removing.\")\n",
    "                    node.untried_moves.remove(move)\n",
    "                    continue # Skip to next iteration if expansion failed\n",
    "\n",
    "            # 3. Simulation (Playout) - WITH HEURISTICS\n",
    "            simulation_board = current_board_state.copy()\n",
    "            sim_player = node.player_at_node\n",
    "\n",
    "            # Check if the node state itself is terminal before starting simulation loop\n",
    "            is_sim_terminal = is_terminal_node(simulation_board)\n",
    "\n",
    "            while not is_sim_terminal:\n",
    "                valid_moves = get_valid_locations(simulation_board)\n",
    "                if not valid_moves:\n",
    "                    is_sim_terminal = True # Draw\n",
    "                    break\n",
    "\n",
    "                # --- START: Heuristic Playout Move Selection ---\n",
    "                chosen_move = None\n",
    "                winning_move_found = False\n",
    "                for m in valid_moves:\n",
    "                    temp_board_win = simulation_board.copy()\n",
    "                    r_win = get_next_open_row(temp_board_win, m)\n",
    "                    drop_piece(temp_board_win, r_win, m, sim_player)\n",
    "                    if winning_move(temp_board_win, sim_player):\n",
    "                        chosen_move = m\n",
    "                        winning_move_found = True\n",
    "                        break\n",
    "                if winning_move_found: pass\n",
    "                else:\n",
    "                    sim_opponent = self.opponent_id if sim_player == self.player_id else self.player_id\n",
    "                    blocking_move_found = False\n",
    "                    for m in valid_moves:\n",
    "                        temp_board_block = simulation_board.copy()\n",
    "                        r_block = get_next_open_row(temp_board_block, m)\n",
    "                        drop_piece(temp_board_block, r_block, m, sim_opponent)\n",
    "                        if winning_move(temp_board_block, sim_opponent):\n",
    "                             chosen_move = m\n",
    "                             blocking_move_found = True\n",
    "                             break\n",
    "                    if blocking_move_found: pass\n",
    "                if not winning_move_found and not blocking_move_found:\n",
    "                    move_values = {}\n",
    "                    for m in valid_moves:\n",
    "                        r = get_next_open_row(simulation_board, m)\n",
    "                        move_values[m] = self.positional_values[r][m]\n",
    "                    total_value = sum(v for v in move_values.values() if v > 0)\n",
    "                    if total_value > 0:\n",
    "                         weights = [max(0, move_values[m]) for m in valid_moves]\n",
    "                         sum_weights = sum(weights)\n",
    "                         if sum_weights > 0:\n",
    "                             probabilities = [w / sum_weights for w in weights]\n",
    "                             chosen_move = random.choices(valid_moves, weights=probabilities, k=1)[0]\n",
    "                         else: chosen_move = random.choice(valid_moves)\n",
    "                    else: chosen_move = random.choice(valid_moves)\n",
    "                # --- END: Heuristic Playout Move Selection ---\n",
    "\n",
    "                row = get_next_open_row(simulation_board, chosen_move)\n",
    "                drop_piece(simulation_board, row, chosen_move, sim_player)\n",
    "                sim_player = self.opponent_id if sim_player == self.player_id else self.player_id # Switch player\n",
    "\n",
    "                # Check if terminal *after* the move\n",
    "                is_sim_terminal = is_terminal_node(simulation_board)\n",
    "\n",
    "\n",
    "            # Determine simulation result (from the final simulation_board state)\n",
    "            winner = None\n",
    "            sim_draw = False\n",
    "            last_player = self.opponent_id if sim_player == self.player_id else self.player_id # Player who made the last move\n",
    "            if winning_move(simulation_board, last_player):\n",
    "                 winner = last_player\n",
    "            # Check for draw only if no winner\n",
    "            elif not get_valid_locations(simulation_board) and not winner:\n",
    "                 sim_draw = True\n",
    "\n",
    "            sim_result_for_mcts_player = 0 # Draw is 0\n",
    "            if winner == self.player_id:\n",
    "                sim_result_for_mcts_player = 1\n",
    "            elif winner == self.opponent_id:\n",
    "                sim_result_for_mcts_player = -1\n",
    "\n",
    "            # 4. Backpropagation\n",
    "            temp_node = node # Start backprop from the node where simulation started\n",
    "            while temp_node is not None:\n",
    "                 result_for_node = sim_result_for_mcts_player if temp_node.player_at_node == self.player_id else -sim_result_for_mcts_player\n",
    "                 temp_node.update(result_for_node)\n",
    "                 temp_node = temp_node.parent\n",
    "\n",
    "        # --- Choose the best move ---\n",
    "        if not root.children:\n",
    "             print(f\"MCTS Player {self.player_id}: Warning - No moves explored/possible after {self.n_iterations} iterations. Choosing random.\")\n",
    "             return random.choice(get_valid_locations(board)) if get_valid_locations(board) else None # Fallback\n",
    "\n",
    "        # Select child with highest number of visits (most robust)\n",
    "        best_child = max(root.children, key=lambda c: c.visits)\n",
    "        best_move = best_child.move\n",
    "\n",
    "        # --- Display Info ---\n",
    "        end_time = time.time()\n",
    "        # Calculate win rate for display (from MCTS player's perspective)\n",
    "        # Score is relative to the child's player. Parent win rate = - (child score / visits)\n",
    "        parent_win_rate_for_best_child = (-best_child.score / best_child.visits) if best_child.visits > 0 else 0.0\n",
    "        win_rate_display = (parent_win_rate_for_best_child + 1) / 2 * 100 # Scale -1..+1 to 0..100%\n",
    "\n",
    "        print(f\"MCTS Player {self.player_id}: Chose column {best_move} \"\n",
    "              f\"({best_child.visits} visits, \"\n",
    "              f\"~WinRate: {win_rate_display:.1f}%, \"\n",
    "              f\"Time: {end_time - start_time:.2f}s)\")\n",
    "\n",
    "        # Sanity check: is the chosen move actually valid?\n",
    "        if best_move not in get_valid_locations(board):\n",
    "             print(f\"MCTS Warning: Chosen best move {best_move} is invalid! Fallback to random.\")\n",
    "             valid_fallback = get_valid_locations(board)\n",
    "             return random.choice(valid_fallback) if valid_fallback else None\n",
    "\n",
    "        return best_move\n",
    "\n",
    "\n",
    "print(\"MCTSPlayer class Updated with Heuristic Playouts and Corrected UCT.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40feabb3-0526-4d17-9dd4-05252a2dcfdf",
   "metadata": {},
   "source": [
    "## Q-Learning Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b41e5a34-3b13-4fcf-992c-8952706bde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QLearningAgent class updated with Verbose Flag for printing control.\n"
     ]
    }
   ],
   "source": [
    "# Q-Learning Agent Class\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Positional Values ---\n",
    "POSITIONAL_VALUES_RAW = np.array([\n",
    "    [3, 4, 5, 7, 5, 4, 3], [4, 6, 8, 10, 8, 6, 4], [5, 8, 11, 13, 11, 8, 5],\n",
    "    [5, 8, 11, 13, 11, 8, 5], [4, 6, 8, 10, 8, 6, 4], [3, 4, 5, 7, 5, 4, 3]\n",
    "])\n",
    "POSITIONAL_VALUES = np.flipud(POSITIONAL_VALUES_RAW)\n",
    "\n",
    "class QLearningAgent(Player):\n",
    "    \"\"\" A Reinforcement Learning agent using Q-learning for Connect 4. \"\"\"\n",
    "    def __init__(self, player_id, learning_rate=0.1, discount_factor=0.9,\n",
    "                 exploration_rate=1.0, exploration_decay=0.9995, min_exploration_rate=0.01):\n",
    "        super().__init__(player_id)\n",
    "        self.opponent_id = PLAYER1_PIECE if player_id == PLAYER2_PIECE else PLAYER2_PIECE\n",
    "        self.q_table = {}\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.epsilon = exploration_rate\n",
    "        self.epsilon_decay = exploration_decay\n",
    "        self.min_epsilon = min_exploration_rate\n",
    "        self.previous_state_tuple = None\n",
    "        self.previous_action = None\n",
    "        self.is_learning = True\n",
    "        self.verbose = False \n",
    "\n",
    "    def _state_to_tuple(self, board): return tuple(map(tuple, board))\n",
    "    \n",
    "    def _flip_state(self, board):\n",
    "        flipped_board = board.copy()\n",
    "        p1_mask, p2_mask = flipped_board == PLAYER1_PIECE, flipped_board == PLAYER2_PIECE\n",
    "        flipped_board[p1_mask], flipped_board[p2_mask] = PLAYER2_PIECE, PLAYER1_PIECE\n",
    "        return flipped_board\n",
    "   \n",
    "    def get_q_value(self, state_tuple, action): return self.q_table.get((state_tuple, action), 0.0)\n",
    "   \n",
    "    def choose_action(self, board):\n",
    "        if self.player_id == PLAYER1_PIECE: lookup_board = board\n",
    "        else: lookup_board = self._flip_state(board)\n",
    "        state_tuple = self._state_to_tuple(lookup_board)\n",
    "        valid_actions = get_valid_locations(board)\n",
    "        details = {'max_q': None, 'chosen_q': None, 'tie_break_used': False, 'exploited': False}\n",
    "        if not valid_actions: return None, details\n",
    "        if self.is_learning and random.uniform(0, 1) < self.epsilon:\n",
    "            chosen_action = random.choice(valid_actions)\n",
    "            details['chosen_q'] = self.get_q_value(state_tuple, chosen_action); details['exploited'] = False\n",
    "            return chosen_action, details\n",
    "        else:\n",
    "            details['exploited'] = True\n",
    "            q_values = {action: self.get_q_value(state_tuple, action) for action in valid_actions}\n",
    "            if not q_values: return random.choice(valid_actions), details\n",
    "            max_q = -float('inf'); tolerance = 1e-9\n",
    "            for q in q_values.values():\n",
    "                 if q > max_q: max_q = q\n",
    "            details['max_q'] = max_q\n",
    "            best_actions = [action for action, q in q_values.items() if abs(q - max_q) < tolerance]\n",
    "            chosen_action = None\n",
    "            if len(best_actions) == 1: chosen_action = best_actions[0]\n",
    "            elif len(best_actions) > 1:\n",
    "                details['tie_break_used'] = True; best_heuristic_value = -float('inf'); tied_heuristic_actions = []\n",
    "                for action in best_actions:\n",
    "                    row = get_next_open_row(board, action)\n",
    "                    if row is not None:\n",
    "                         heuristic_value = POSITIONAL_VALUES[row][action]\n",
    "                         if heuristic_value > best_heuristic_value: best_heuristic_value = heuristic_value; tied_heuristic_actions = [action]\n",
    "                         elif heuristic_value == best_heuristic_value: tied_heuristic_actions.append(action)\n",
    "                if tied_heuristic_actions: chosen_action = random.choice(tied_heuristic_actions)\n",
    "                else: chosen_action = random.choice(best_actions)\n",
    "            else: chosen_action = random.choice(valid_actions)\n",
    "            details['chosen_q'] = q_values.get(chosen_action, 0.0)\n",
    "            return chosen_action, details\n",
    "\n",
    "\n",
    "    def get_move(self, board):\n",
    "        \"\"\"Gets the agent's move. Prints details ONLY if self.verbose is True.\"\"\"\n",
    "        start_time = time.time()\n",
    "        chosen_action, details = self.choose_action(board.copy())\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        if chosen_action is None:\n",
    "            print(f\"Q-Agent {self.player_id}: No valid moves available.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        if self.verbose:\n",
    "            max_q_str = f\"{details['max_q']:.4f}\" if details['max_q'] is not None else \"N/A\"\n",
    "            chosen_q_str = f\"{details['chosen_q']:.4f}\" if details['chosen_q'] is not None else \"N/A\"\n",
    "            mode = \"Exploit\" if details['exploited'] else \"Explore\"\n",
    "            tie_info = \"(TIEBREAK)\" if details['tie_break_used'] else \"\"\n",
    "\n",
    "            print(f\"Q-Agent {self.player_id}: Chose column {chosen_action} \"\n",
    "                  f\"({mode}{tie_info}, \"\n",
    "                  f\"ChosenQ: {chosen_q_str}, MaxQ: {max_q_str}, \"\n",
    "                  f\"Time: {elapsed_time:.3f}s)\")\n",
    "\n",
    "\n",
    "        # Store state/action for learning (runs ONLY if learning is enabled)\n",
    "        if self.is_learning:\n",
    "            self.previous_state_tuple = self._state_to_tuple(board)\n",
    "            self.previous_action = chosen_action\n",
    "\n",
    "        return chosen_action\n",
    "\n",
    "\n",
    "    def learn(self, reward, next_board):\n",
    "        if not self.is_learning or self.previous_state_tuple is None or self.previous_action is None: return\n",
    "        old_q = self.get_q_value(self.previous_state_tuple, self.previous_action)\n",
    "        if self.player_id == PLAYER1_PIECE: lookup_next_board = next_board\n",
    "        else: lookup_next_board = self._flip_state(next_board)\n",
    "        next_state_tuple = self._state_to_tuple(lookup_next_board)\n",
    "        valid_next_actions = get_valid_locations(next_board)\n",
    "        max_future_q = 0.0\n",
    "        if not is_terminal_node(next_board) and valid_next_actions:\n",
    "            q_values_next = [self.get_q_value(next_state_tuple, action) for action in valid_next_actions]\n",
    "            if q_values_next: max_future_q = max(q_values_next)\n",
    "        new_q = old_q + self.lr * (reward + self.gamma * max_future_q - old_q)\n",
    "        self.q_table[(self.previous_state_tuple, self.previous_action)] = new_q\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        if self.is_learning: self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def save_q_table(self, filepath=\"q_table.pkl\"):\n",
    "        temp_filepath = filepath + \".tmp\"; final_filepath = filepath\n",
    "        try:\n",
    "            with open(temp_filepath, 'wb') as f: pickle.dump(self.q_table, f)\n",
    "            os.replace(temp_filepath, final_filepath)\n",
    "            print(f\"Q-table saved successfully to {final_filepath} ({len(self.q_table)} entries)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving Q-table: {e}\")\n",
    "            if os.path.exists(temp_filepath):\n",
    "                try: os.remove(temp_filepath)\n",
    "                except Exception as e_rem: print(f\"Error removing temp file: {e_rem}\")\n",
    "\n",
    "    def load_q_table(self, filepath=\"q_table.pkl\"):\n",
    "        try:\n",
    "            if os.path.exists(filepath):\n",
    "                with open(filepath, 'rb') as f: self.q_table = pickle.load(f)\n",
    "                print(f\"Q-table loaded successfully from {filepath} ({len(self.q_table)} entries)\")\n",
    "            else:\n",
    "                print(f\"Q-table file not found at {filepath}. Starting fresh.\"); self.q_table = {}\n",
    "        except (pickle.UnpicklingError, EOFError, ValueError) as e_load:\n",
    "            print(f\"Error loading Q-table from {filepath}: File might be corrupted or incompatible. {e_load}\")\n",
    "            print(\"Starting with an empty Q-table.\"); self.q_table = {}\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred loading Q-table: {e}\"); self.q_table = {}\n",
    "\n",
    "\n",
    "print(\"QLearningAgent class updated with Verbose Flag for printing control.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc976ec0-e479-40b9-bd1c-5351d928d008",
   "metadata": {},
   "source": [
    "## Training Loop for Q-Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5f81b370-f3c4-4235-a60a-cdc9f852f8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table loaded successfully from connect4_q_agent_heuristic.pkl (307021 entries)\n",
      "SlightlyBetterRandomAIPlayer initialized for Player 2 (Opponent: 1)\n",
      "\n",
      "--- Starting Q-Learning Training with Heuristics (100000 episodes) ---\n",
      "Agent: QLearningAgent (P1) vs Opponent: SlightlyBetterRandomAIPlayer (P2)\n",
      "Heuristic Weight: 0.01\n",
      "Initial Epsilon: 1.0000, Q-table size: 307021\n",
      "Ep: 5000/100000 | Eps: 0.0820 | Q-Size: 335345 | Last 5000: W:1352(27.0%) L:3608 D:40 | Avg Time/Ep: 0.018s\n",
      "Ep: 10000/100000 | Eps: 0.0100 | Q-Size: 350094 | Last 5000: W:2662(53.2%) L:2284 D:54 | Avg Time/Ep: 0.018s\n",
      "Error saving Q-table: \n",
      "Ep: 15000/100000 | Eps: 0.0100 | Q-Size: 362208 | Last 5000: W:2969(59.4%) L:1943 D:88 | Avg Time/Ep: 0.020s\n",
      "Ep: 20000/100000 | Eps: 0.0100 | Q-Size: 373991 | Last 5000: W:2971(59.4%) L:1936 D:93 | Avg Time/Ep: 0.019s\n",
      "Error saving Q-table: \n",
      "Ep: 25000/100000 | Eps: 0.0100 | Q-Size: 385876 | Last 5000: W:2965(59.3%) L:1950 D:85 | Avg Time/Ep: 0.021s\n",
      "Ep: 30000/100000 | Eps: 0.0100 | Q-Size: 397621 | Last 5000: W:3052(61.0%) L:1881 D:67 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 35000/100000 | Eps: 0.0100 | Q-Size: 409065 | Last 5000: W:3074(61.5%) L:1839 D:87 | Avg Time/Ep: 0.021s\n",
      "Ep: 40000/100000 | Eps: 0.0100 | Q-Size: 420307 | Last 5000: W:3125(62.5%) L:1786 D:89 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 45000/100000 | Eps: 0.0100 | Q-Size: 431804 | Last 5000: W:3107(62.1%) L:1829 D:64 | Avg Time/Ep: 0.020s\n",
      "Ep: 50000/100000 | Eps: 0.0100 | Q-Size: 442887 | Last 5000: W:3097(61.9%) L:1833 D:70 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 55000/100000 | Eps: 0.0100 | Q-Size: 453614 | Last 5000: W:3118(62.4%) L:1807 D:75 | Avg Time/Ep: 0.020s\n",
      "Ep: 60000/100000 | Eps: 0.0100 | Q-Size: 464405 | Last 5000: W:3146(62.9%) L:1773 D:81 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 65000/100000 | Eps: 0.0100 | Q-Size: 474787 | Last 5000: W:3219(64.4%) L:1694 D:87 | Avg Time/Ep: 0.020s\n",
      "Ep: 70000/100000 | Eps: 0.0100 | Q-Size: 485418 | Last 5000: W:3212(64.2%) L:1704 D:84 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 75000/100000 | Eps: 0.0100 | Q-Size: 495883 | Last 5000: W:3163(63.3%) L:1749 D:88 | Avg Time/Ep: 0.020s\n",
      "Ep: 80000/100000 | Eps: 0.0100 | Q-Size: 505950 | Last 5000: W:3202(64.0%) L:1703 D:95 | Avg Time/Ep: 0.020s\n",
      "Error saving Q-table: \n",
      "Ep: 85000/100000 | Eps: 0.0100 | Q-Size: 516243 | Last 5000: W:3201(64.0%) L:1728 D:71 | Avg Time/Ep: 0.020s\n",
      "Ep: 90000/100000 | Eps: 0.0100 | Q-Size: 526308 | Last 5000: W:3224(64.5%) L:1700 D:76 | Avg Time/Ep: 0.019s\n",
      "Error saving Q-table: \n",
      "Ep: 95000/100000 | Eps: 0.0100 | Q-Size: 536257 | Last 5000: W:3199(64.0%) L:1724 D:77 | Avg Time/Ep: 0.020s\n",
      "Ep: 100000/100000 | Eps: 0.0100 | Q-Size: 546198 | Last 5000: W:3308(66.2%) L:1603 D:89 | Avg Time/Ep: 0.019s\n",
      "Error saving Q-table: \n",
      "\n",
      "--- Training Finished ---\n",
      "Total time: 1981.62 seconds\n",
      "Final Epsilon: 0.0100\n",
      "Final Q-table size: 546198\n",
      "Overall Stats: Wins: 60366, Losses: 38074, Draws: 1560\n",
      "Error saving Q-table: \n",
      "\n",
      "Agent set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "# Training Loop for Q-Learning Agent\n",
    "\n",
    "# --- Training Configuration ---\n",
    "N_EPISODES = 100000       \n",
    "PRINT_EVERY = 5000\n",
    "SAVE_EVERY = 10000\n",
    "\n",
    "# Rewards\n",
    "WIN_REWARD = 10.0\n",
    "LOSS_REWARD = -10.0\n",
    "DRAW_REWARD = -1.0         \n",
    "# STEP_REWARD = -0.01      \n",
    "STEP_REWARD = 0.0        \n",
    "\n",
    "# --- Heuristic Reward Shaping ---\n",
    "\n",
    "\n",
    "HEURISTIC_WEIGHT = 0.01 # Weight for the positional value bonus. We can try different values here (0.005, 0.01, 0.02)\n",
    "\n",
    "\n",
    "\n",
    "Q_TABLE_FILE = \"connect4_q_agent_heuristic.pkl\" \n",
    "\n",
    "# --- Opponent ---\n",
    "opponent_player_class = SlightlyBetterRandomAIPlayer\n",
    "\n",
    "# --- Initialize Agent ---\n",
    "q_agent = QLearningAgent(player_id=PLAYER1_PIECE)\n",
    "q_agent.load_q_table(Q_TABLE_FILE)\n",
    "q_agent.is_learning = True\n",
    "\n",
    "opponent = opponent_player_class(PLAYER2_PIECE)\n",
    "\n",
    "# --- Training Statistics ---\n",
    "win_count = 0\n",
    "loss_count = 0\n",
    "draw_count = 0\n",
    "recent_outcomes = []\n",
    "\n",
    "print(f\"\\n--- Starting Q-Learning Training with Heuristics ({N_EPISODES} episodes) ---\")\n",
    "print(f\"Agent: {type(q_agent).__name__} (P1) vs Opponent: {type(opponent).__name__} (P2)\")\n",
    "print(f\"Heuristic Weight: {HEURISTIC_WEIGHT}\")\n",
    "print(f\"Initial Epsilon: {q_agent.epsilon:.4f}, Q-table size: {len(q_agent.q_table)}\")\n",
    "\n",
    "start_total_time = time.time()\n",
    "\n",
    "for episode in range(1, N_EPISODES + 1):\n",
    "    board = create_board()\n",
    "    game_over = False\n",
    "    turn = 0\n",
    "    last_agent_state = None\n",
    "\n",
    "    while not game_over:\n",
    "        current_player_obj = q_agent if turn == 0 else opponent\n",
    "        player_piece = PLAYER1_PIECE if turn == 0 else PLAYER2_PIECE\n",
    "\n",
    "        # --- Get Move ---\n",
    "        col = current_player_obj.get_move(board.copy())\n",
    "\n",
    "        if col is None or not is_valid_location(board, col):\n",
    "             print(f\"Episode {episode}: Invalid move {col} by Player {player_piece}. Ending episode.\")\n",
    "             game_over = True\n",
    "             if turn == 0: q_agent.learn(LOSS_REWARD * 2, board)\n",
    "             break\n",
    "\n",
    "        row = get_next_open_row(board, col)\n",
    "        drop_piece(board, row, col, player_piece)\n",
    "        next_board_state = board.copy()\n",
    "\n",
    "        # --- Determine Reward ---\n",
    "        step_reward_value = STEP_REWARD # Start with base step reward\n",
    "        final_reward = None # Will be set if game ends\n",
    "\n",
    "        if winning_move(board, player_piece):\n",
    "            game_over = True\n",
    "            if player_piece == q_agent.player_id:\n",
    "                final_reward = WIN_REWARD\n",
    "                win_count += 1\n",
    "                outcome = 'W'\n",
    "            else: # Opponent won\n",
    "                final_reward = LOSS_REWARD\n",
    "                loss_count += 1\n",
    "                outcome = 'L'\n",
    "\n",
    "        elif len(get_valid_locations(board)) == 0: # Draw\n",
    "            game_over = True\n",
    "            final_reward = DRAW_REWARD\n",
    "            draw_count += 1\n",
    "            outcome = 'D'\n",
    "\n",
    "        else: # Game continues\n",
    "            outcome = None\n",
    "            # --- Apply Heuristic Reward Shaping IF agent just moved ---\n",
    "            if turn == 0:\n",
    "                positional_bonus = POSITIONAL_VALUES[row][col] * HEURISTIC_WEIGHT\n",
    "                step_reward_value += positional_bonus\n",
    "\n",
    "        # --- Agent Learning Step ---\n",
    "        # Learn based on the transition caused BY THE PREVIOUS ACTION stored in the agent\n",
    "        if q_agent.previous_state_tuple:\n",
    "             # Determine the reward to use for the *previous* step's learning update\n",
    "             learn_reward = final_reward if game_over else step_reward_value\n",
    "             q_agent.learn(learn_reward, next_board_state) # next_board_state is the result of the current move\n",
    "\n",
    "\n",
    "        # --- Switch Turn ---\n",
    "        if not game_over:\n",
    "            turn = 1 - turn\n",
    "\n",
    "    # --- End of Episode ---\n",
    "    q_agent.update_epsilon()\n",
    "    if outcome: recent_outcomes.append(outcome)\n",
    "\n",
    "    # --- Print Progress & Save ---\n",
    "    if episode % PRINT_EVERY == 0:\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_total_time\n",
    "        avg_time = elapsed / episode if episode > 0 else 0\n",
    "        recent_window = recent_outcomes[-PRINT_EVERY:]\n",
    "        recent_wins = recent_window.count('W')\n",
    "        recent_losses = recent_window.count('L')\n",
    "        recent_draws = recent_window.count('D')\n",
    "        recent_total = len(recent_window)\n",
    "        win_rate = recent_wins / recent_total * 100 if recent_total > 0 else 0\n",
    "        print(f\"Ep: {episode}/{N_EPISODES} | \"\n",
    "              f\"Eps: {q_agent.epsilon:.4f} | \"\n",
    "              f\"Q-Size: {len(q_agent.q_table)} | \"\n",
    "              f\"Last {PRINT_EVERY}: W:{recent_wins}({win_rate:.1f}%) L:{recent_losses} D:{recent_draws} | \"\n",
    "              f\"Avg Time/Ep: {avg_time:.3f}s\")\n",
    "    if episode % SAVE_EVERY == 0:\n",
    "         q_agent.save_q_table(Q_TABLE_FILE)\n",
    "\n",
    "\n",
    "# --- End of Training ---\n",
    "total_time = time.time() - start_total_time\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(f\"Final Epsilon: {q_agent.epsilon:.4f}\")\n",
    "print(f\"Final Q-table size: {len(q_agent.q_table)}\")\n",
    "print(f\"Overall Stats: Wins: {win_count}, Losses: {loss_count}, Draws: {draw_count}\")\n",
    "q_agent.save_q_table(Q_TABLE_FILE)\n",
    "q_agent.is_learning = False\n",
    "q_agent.epsilon = 0\n",
    "print(\"\\nAgent set to evaluation mode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe908455-8d20-4c8a-96ce-095c2d8cd803",
   "metadata": {},
   "source": [
    "## Training Loop for Q-Learning Agent - gen 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "98cbba9c-0989-4f76-b949-97438dfa4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FIXED Opponent (Player 2) policy from: connect4_q_agent_heuristic.pkl\n",
      "Q-table loaded successfully from connect4_q_agent_heuristic.pkl (307021 entries)\n",
      "Opponent Q-table loaded (307021 entries).\n",
      "Opponent agent set to evaluation mode (no learning, no exploration).\n",
      "\n",
      "Initializing NEW Agent (Player 1) for self-play training...\n",
      "Trainer agent (P1) initialized (Gamma: 0.99, Epsilon Decay: 0.9999, Min Epsilon: 0.05).\n",
      "\n",
      "--- Starting Q-Learning Self-Play Training (100000 episodes) ---\n",
      "Agent: QLearningAgent (Trainer, P1) vs Opponent: QLearningAgent (Fixed, P2)\n",
      "Saving trained agent to: connect4_q_agent_selfplay_gen2.pkl\n",
      "Initial Epsilon: 1.0000, Initial Q-table size: 0\n",
      "Ep: 5000/100000 | Eps: 0.6065 | Q-Size: 14230 | Last 5000: W:1810(36.2%) L:3189 D:1 | Avg Time/Ep: 0.004s\n",
      "Ep: 10000/100000 | Eps: 0.3679 | Q-Size: 20968 | Last 5000: W:3192(63.8%) L:1805 D:3 | Avg Time/Ep: 0.003s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (20968 entries)\n",
      "Ep: 15000/100000 | Eps: 0.2231 | Q-Size: 23032 | Last 5000: W:4146(82.9%) L:852 D:2 | Avg Time/Ep: 0.003s\n",
      "Ep: 20000/100000 | Eps: 0.1353 | Q-Size: 23752 | Last 5000: W:4589(91.8%) L:408 D:3 | Avg Time/Ep: 0.003s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (23752 entries)\n",
      "Ep: 25000/100000 | Eps: 0.0821 | Q-Size: 23989 | Last 5000: W:4767(95.3%) L:233 D:0 | Avg Time/Ep: 0.003s\n",
      "Ep: 30000/100000 | Eps: 0.0500 | Q-Size: 24044 | Last 5000: W:4886(97.7%) L:114 D:0 | Avg Time/Ep: 0.003s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24044 entries)\n",
      "Ep: 35000/100000 | Eps: 0.0500 | Q-Size: 24062 | Last 5000: W:4912(98.2%) L:88 D:0 | Avg Time/Ep: 0.003s\n",
      "Ep: 40000/100000 | Eps: 0.0500 | Q-Size: 24096 | Last 5000: W:4912(98.2%) L:88 D:0 | Avg Time/Ep: 0.003s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24096 entries)\n",
      "Ep: 45000/100000 | Eps: 0.0500 | Q-Size: 24163 | Last 5000: W:4916(98.3%) L:84 D:0 | Avg Time/Ep: 0.003s\n",
      "Ep: 50000/100000 | Eps: 0.0500 | Q-Size: 24183 | Last 5000: W:4926(98.5%) L:74 D:0 | Avg Time/Ep: 0.003s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24183 entries)\n",
      "Ep: 55000/100000 | Eps: 0.0500 | Q-Size: 24226 | Last 5000: W:4905(98.1%) L:93 D:2 | Avg Time/Ep: 0.002s\n",
      "Ep: 60000/100000 | Eps: 0.0500 | Q-Size: 24266 | Last 5000: W:4913(98.3%) L:87 D:0 | Avg Time/Ep: 0.002s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24266 entries)\n",
      "Ep: 65000/100000 | Eps: 0.0500 | Q-Size: 24293 | Last 5000: W:4918(98.4%) L:81 D:1 | Avg Time/Ep: 0.002s\n",
      "Ep: 70000/100000 | Eps: 0.0500 | Q-Size: 24329 | Last 5000: W:4916(98.3%) L:84 D:0 | Avg Time/Ep: 0.002s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24329 entries)\n",
      "Ep: 75000/100000 | Eps: 0.0500 | Q-Size: 24349 | Last 5000: W:4928(98.6%) L:71 D:1 | Avg Time/Ep: 0.002s\n",
      "Ep: 80000/100000 | Eps: 0.0500 | Q-Size: 24379 | Last 5000: W:4919(98.4%) L:81 D:0 | Avg Time/Ep: 0.002s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24379 entries)\n",
      "Ep: 85000/100000 | Eps: 0.0500 | Q-Size: 24430 | Last 5000: W:4921(98.4%) L:78 D:1 | Avg Time/Ep: 0.002s\n",
      "Ep: 90000/100000 | Eps: 0.0500 | Q-Size: 24469 | Last 5000: W:4910(98.2%) L:89 D:1 | Avg Time/Ep: 0.002s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24469 entries)\n",
      "Ep: 95000/100000 | Eps: 0.0500 | Q-Size: 24481 | Last 5000: W:4929(98.6%) L:71 D:0 | Avg Time/Ep: 0.002s\n",
      "Ep: 100000/100000 | Eps: 0.0500 | Q-Size: 24526 | Last 5000: W:4904(98.1%) L:96 D:0 | Avg Time/Ep: 0.002s\n",
      "Q-table saved successfully to connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "\n",
      "--- Self-Play Training Finished ---\n",
      "Total time: 235.95 seconds\n",
      "Final Epsilon: 0.0500\n",
      "Final Q-table size: 24526\n",
      "Overall Stats: Wins: 92219, Losses: 7766, Draws: 15\n",
      "\n",
      "Trainer agent saved to connect4_q_agent_selfplay_gen2.pkl and set to evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "# Q-Learning Self-Play Training Loop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# --- Training Configuration ---\n",
    "N_EPISODES = 100000     \n",
    "PRINT_EVERY = 5000\n",
    "SAVE_EVERY = 10000       \n",
    "\n",
    "# Rewards (Keep consistent unless you have a reason to change)\n",
    "WIN_REWARD = 10.0\n",
    "LOSS_REWARD = -10.0\n",
    "DRAW_REWARD = -1.0\n",
    "STEP_REWARD = 0.0\n",
    "\n",
    "# Heuristic Weight (Keep or adjust for the agent being trained)\n",
    "HEURISTIC_WEIGHT = 0.01\n",
    "\n",
    "# --- File Paths ---\n",
    "EXISTING_Q_TABLE_FILE = \"connect4_q_agent_heuristic.pkl\" # Load previous agent from here\n",
    "NEW_Q_TABLE_FILE = \"connect4_q_agent_selfplay_gen2.pkl\" # Save NEW agent here\n",
    "\n",
    "# --- Initialize Agents ---\n",
    "players_ready = True\n",
    "q_agent_opponent = None # The fixed opponent (loads existing table)\n",
    "q_agent_trainer = None  # The agent being trained (starts fresh or from existing)\n",
    "\n",
    "# 1. Initialize Opponent Agent (Fixed Policy)\n",
    "try:\n",
    "    print(f\"Loading FIXED Opponent (Player 2) policy from: {EXISTING_Q_TABLE_FILE}\")\n",
    "    q_agent_opponent = QLearningAgent(player_id=PLAYER2_PIECE) # Assign as P2\n",
    "\n",
    "    # Load the previously trained Q-table\n",
    "    q_agent_opponent.load_q_table(EXISTING_Q_TABLE_FILE)\n",
    "    if not q_agent_opponent.q_table:\n",
    "         print(f\"WARNING: Opponent Q-table file '{EXISTING_Q_TABLE_FILE}' not found or loaded empty.\")\n",
    "         # Decide if you want to stop or proceed with a 'dumb' opponent\n",
    "    else:\n",
    "        print(f\"Opponent Q-table loaded ({len(q_agent_opponent.q_table)} entries).\")\n",
    "\n",
    "    # CRITICAL: Set opponent to EVALUATION mode\n",
    "    q_agent_opponent.is_learning = False\n",
    "    q_agent_opponent.epsilon = 0.0\n",
    "    print(\"Opponent agent set to evaluation mode (no learning, no exploration).\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: 'QLearningAgent' class not defined.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Existing Q-table file '{EXISTING_Q_TABLE_FILE}' not found.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Opponent Agent: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "\n",
    "# 2. Initialize Agent to be Trained (Self-Play)\n",
    "if players_ready:\n",
    "    try:\n",
    "        print(\"\\nInitializing NEW Agent (Player 1) for self-play training...\")\n",
    "        # Option 1: Start training from scratch\n",
    "        q_agent_trainer = QLearningAgent(\n",
    "            player_id=PLAYER1_PIECE,\n",
    "            learning_rate=0.1,        \n",
    "            discount_factor=0.99,     \n",
    "            exploration_rate=1.0,     \n",
    "            exploration_decay=0.9999, \n",
    "            min_exploration_rate=0.05 \n",
    "        )\n",
    "\n",
    "        # Ensure trainer is set to LEARNING mode\n",
    "        q_agent_trainer.is_learning = True\n",
    "        print(f\"Trainer agent (P1) initialized (Gamma: {q_agent_trainer.gamma}, Epsilon Decay: {q_agent_trainer.epsilon_decay}, Min Epsilon: {q_agent_trainer.min_epsilon}).\")\n",
    "\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: 'QLearningAgent' class not defined.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the Trainer Agent: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "# --- Training Loop ---\n",
    "if players_ready and q_agent_trainer and q_agent_opponent:\n",
    "    win_count = 0\n",
    "    loss_count = 0\n",
    "    draw_count = 0\n",
    "    recent_outcomes = []\n",
    "\n",
    "    print(f\"\\n--- Starting Q-Learning Self-Play Training ({N_EPISODES} episodes) ---\")\n",
    "    print(f\"Agent: QLearningAgent (Trainer, P1) vs Opponent: QLearningAgent (Fixed, P2)\")\n",
    "    print(f\"Saving trained agent to: {NEW_Q_TABLE_FILE}\")\n",
    "    print(f\"Initial Epsilon: {q_agent_trainer.epsilon:.4f}, Initial Q-table size: {len(q_agent_trainer.q_table)}\")\n",
    "\n",
    "    start_total_time = time.time()\n",
    "\n",
    "    for episode in range(1, N_EPISODES + 1):\n",
    "        board = create_board()\n",
    "        game_over = False\n",
    "        turn = 0 # 0 for Trainer (P1), 1 for Opponent (P2)\n",
    "\n",
    "        # Reset the trainer's previous state/action at the start of each episode\n",
    "        q_agent_trainer.previous_state_tuple = None\n",
    "        q_agent_trainer.previous_action = None\n",
    "\n",
    "        while not game_over:\n",
    "            # Determine current player object\n",
    "            current_player_obj = q_agent_trainer if turn == 0 else q_agent_opponent\n",
    "            player_piece = PLAYER1_PIECE if turn == 0 else PLAYER2_PIECE\n",
    "\n",
    "            # --- Get Move ---\n",
    "            # Opponent uses its fixed policy; Trainer uses its learning policy\n",
    "            col = current_player_obj.get_move(board.copy())\n",
    "\n",
    "            if col is None or not is_valid_location(board, col):\n",
    "                 print(f\"Episode {episode}: Invalid move {col} by Player {player_piece} ({type(current_player_obj).__name__}). Ending.\")\n",
    "                 # Penalize heavily if the trainer made the invalid move\n",
    "                 if turn == 0:\n",
    "                      # Use learn method with a large penalty\n",
    "                      if q_agent_trainer.previous_state_tuple and q_agent_trainer.previous_action is not None:\n",
    "                           q_agent_trainer.learn(LOSS_REWARD * 2, board) # Penalize based on previous state/action\n",
    "                      else: # If it's the very first move\n",
    "                           # Cannot learn directly, just record loss\n",
    "                           loss_count += 1\n",
    "                           outcome = 'L'\n",
    "                 game_over = True\n",
    "                 break # End episode\n",
    "\n",
    "            row = get_next_open_row(board, col)\n",
    "            drop_piece(board, row, col, player_piece)\n",
    "            next_board_state = board.copy()\n",
    "\n",
    "            # --- Determine Reward ---\n",
    "            step_reward_value = STEP_REWARD\n",
    "            final_reward = None\n",
    "            outcome = None\n",
    "\n",
    "            if winning_move(board, player_piece):\n",
    "                game_over = True\n",
    "                if player_piece == q_agent_trainer.player_id: # Trainer won\n",
    "                    final_reward = WIN_REWARD\n",
    "                    win_count += 1\n",
    "                    outcome = 'W'\n",
    "                else: # Opponent won (Trainer lost)\n",
    "                    final_reward = LOSS_REWARD\n",
    "                    loss_count += 1\n",
    "                    outcome = 'L'\n",
    "            elif len(get_valid_locations(board)) == 0: # Draw\n",
    "                game_over = True\n",
    "                final_reward = DRAW_REWARD\n",
    "                draw_count += 1\n",
    "                outcome = 'D'\n",
    "            else: # Game continues\n",
    "                # Apply Heuristic Reward Shaping IF trainer just moved\n",
    "                if turn == 0: # Trainer (P1) just moved\n",
    "                    positional_bonus = POSITIONAL_VALUES[row][col] * HEURISTIC_WEIGHT\n",
    "                    step_reward_value += positional_bonus\n",
    "\n",
    "\n",
    "            # Learn based on the transition caused BY THE TRAINER'S LAST ACTION\n",
    "            if q_agent_trainer.previous_state_tuple and q_agent_trainer.previous_action is not None:\n",
    "                 # If game ended, use final reward. Otherwise, use step reward.\n",
    "                 learn_reward = final_reward if game_over else step_reward_value\n",
    "                 q_agent_trainer.learn(learn_reward, next_board_state)\n",
    "\n",
    "                 # Reset after learning from this step to avoid reusing old state if opponent plays invalid move\n",
    "                 if not game_over: \n",
    "                    pass \n",
    "\n",
    "            # --- Switch Turn ---\n",
    "            if not game_over:\n",
    "                turn = 1 - turn\n",
    "\n",
    "        # --- End of Episode ---\n",
    "        q_agent_trainer.update_epsilon() # Decay trainer's epsilon\n",
    "        if outcome: recent_outcomes.append(outcome)\n",
    "\n",
    "        # --- Print Progress & Save ---\n",
    "        if episode % PRINT_EVERY == 0:\n",
    "            end_time = time.time()\n",
    "            elapsed = end_time - start_total_time\n",
    "            # Calculate avg time per episode more robustly\n",
    "            avg_time = (elapsed / episode) if episode > 0 else 0\n",
    "\n",
    "            recent_window = recent_outcomes[-PRINT_EVERY:]\n",
    "            recent_wins = recent_window.count('W')\n",
    "            recent_losses = recent_window.count('L')\n",
    "            recent_draws = recent_window.count('D')\n",
    "            recent_total = len(recent_window)\n",
    "            win_rate = recent_wins / recent_total * 100 if recent_total > 0 else 0\n",
    "\n",
    "            print(f\"Ep: {episode}/{N_EPISODES} | \"\n",
    "                  f\"Eps: {q_agent_trainer.epsilon:.4f} | \"\n",
    "                  f\"Q-Size: {len(q_agent_trainer.q_table)} | \"\n",
    "                  f\"Last {PRINT_EVERY}: W:{recent_wins}({win_rate:.1f}%) L:{recent_losses} D:{recent_draws} | \"\n",
    "                  f\"Avg Time/Ep: {avg_time:.3f}s\")\n",
    "\n",
    "        if episode % SAVE_EVERY == 0 or episode == N_EPISODES: # Save also on last episode\n",
    "             # Save the TRAINER's Q-table to the NEW file\n",
    "             q_agent_trainer.save_q_table(NEW_Q_TABLE_FILE)\n",
    "\n",
    "\n",
    "    # --- End of Training ---\n",
    "    total_time = time.time() - start_total_time\n",
    "    print(\"\\n--- Self-Play Training Finished ---\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"Final Epsilon: {q_agent_trainer.epsilon:.4f}\")\n",
    "    print(f\"Final Q-table size: {len(q_agent_trainer.q_table)}\")\n",
    "    print(f\"Overall Stats: Wins: {win_count}, Losses: {loss_count}, Draws: {draw_count}\")\n",
    "    # Final save is handled in the loop now\n",
    "    q_agent_trainer.is_learning = False\n",
    "    q_agent_trainer.epsilon = 0 # Set trainer to eval mode after training\n",
    "    print(f\"\\nTrainer agent saved to {NEW_Q_TABLE_FILE} and set to evaluation mode.\")\n",
    "\n",
    "else:\n",
    "     print(\"\\nAgent initialization failed. Cannot start training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b0bd6-cd1a-464b-a426-572247e1b59d",
   "metadata": {},
   "source": [
    "## AI Player - Hybrid MCTS Q-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f4064f01-04b6-4b17-b697-047860368931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS_QAgent_Hybrid class defined (with debugging).\n"
     ]
    }
   ],
   "source": [
    "# Hybrid MCTS + Q-Agent Player\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import os # Added os for path checks if needed later\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- MCTS Node ---\n",
    "class MCTSNode:\n",
    "    \"\"\" Represents a node in the Monte Carlo Search Tree. \"\"\"\n",
    "    def __init__(self, state, parent=None, move=None, player_at_node=None):\n",
    "        self.state = state; self.parent = parent; self.move = move\n",
    "        self.children = []; self.visits = 0; self.score = 0\n",
    "        self.untried_moves = get_valid_locations(state); self.player_at_node = player_at_node\n",
    "\n",
    "    def uct_select_child(self, exploration_constant=1.414):\n",
    "        \"\"\" Selects a child node using the UCT formula, from the parent's perspective. \"\"\"\n",
    "        if not self.children: return None\n",
    "        if self.visits == 0: return random.choice(self.children) if self.children else None\n",
    "        log_parent_visits = math.log(self.visits)\n",
    "        def uct_score(node):\n",
    "            if node.visits == 0: return float('inf')\n",
    "            child_player_win_rate = node.score / node.visits\n",
    "            parent_perspective_win_rate = -child_player_win_rate\n",
    "            exploration_term = exploration_constant * math.sqrt(log_parent_visits / node.visits)\n",
    "            return parent_perspective_win_rate + exploration_term\n",
    "        return max(self.children, key=uct_score)\n",
    "\n",
    "    def add_child(self, move, state, player_at_new_node):\n",
    "        \"\"\" Adds a new child node. \"\"\"\n",
    "        node = MCTSNode(state=state, parent=self, move=move, player_at_node=player_at_new_node)\n",
    "        # Ensure move exists before trying to remove (should always be true if called correctly)\n",
    "        if move in self.untried_moves:\n",
    "             self.untried_moves.remove(move)\n",
    "        else:\n",
    "             pass\n",
    "        self.children.append(node); return node\n",
    "\n",
    "    def update(self, result_from_perspective_of_player_at_this_node):\n",
    "        \"\"\" Updates visit count and score. \"\"\"\n",
    "        self.visits += 1; self.score += result_from_perspective_of_player_at_this_node\n",
    "\n",
    "\n",
    "\n",
    "# --- Hybrid Player ---\n",
    "class MCTS_QAgent_Hybrid(Player):\n",
    "    \"\"\" Combines MCTS search with Q-Agent guided simulations. \"\"\"\n",
    "\n",
    "    def __init__(self, player_id, q_table_path, iterations=1000, exploration_constant=1.414):\n",
    "        super().__init__(player_id)\n",
    "        self.opponent_id = PLAYER1_PIECE if player_id == PLAYER2_PIECE else PLAYER2_PIECE\n",
    "        self.n_iterations = iterations\n",
    "        self.exploration_constant = exploration_constant\n",
    "\n",
    "        # --- Load the Q-Agent for internal use ---\n",
    "        self.q_agent = None\n",
    "        print(f\"Initializing Hybrid Agent (Player {player_id})\")\n",
    "        try:\n",
    "            self.q_agent = QLearningAgent(player_id=PLAYER1_PIECE) # Internal agent always thinks it's P1\n",
    "            self.q_agent.load_q_table(q_table_path)\n",
    "            if not self.q_agent.q_table:\n",
    "                print(f\"WARNING: Q-table file '{q_table_path}' loaded empty for Hybrid agent.\")\n",
    "            self.q_agent.is_learning = False\n",
    "            self.q_agent.epsilon = 0.0\n",
    "            self.q_agent.verbose = False\n",
    "            print(f\"Internal Q-Agent loaded ({len(self.q_agent.q_table)} entries) for Hybrid Player {player_id}.\")\n",
    "        except NameError:\n",
    "            print(\"ERROR: QLearningAgent class not defined. Cannot create Hybrid Agent.\")\n",
    "            raise\n",
    "        except FileNotFoundError:\n",
    "             print(f\"ERROR: Q-table file '{q_table_path}' not found for Hybrid Agent.\")\n",
    "             raise\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR loading Q-table for Hybrid Agent: {e}\")\n",
    "            raise\n",
    "\n",
    "        if self.q_agent is None:\n",
    "             raise ValueError(\"Failed to initialize internal Q-Agent for Hybrid player.\")\n",
    "\n",
    "\n",
    "    def _simulate_with_q_agent(self, board_state, starting_player):\n",
    "        \"\"\" Performs a playout using the Q-agent to choose moves. \"\"\"\n",
    "        simulation_board = board_state.copy()\n",
    "        sim_player = starting_player\n",
    "\n",
    "        try: # Added try-except block for better debugging within simulation\n",
    "            # Initial check before loop\n",
    "            initial_terminal_check = is_terminal_node(simulation_board)\n",
    "            is_sim_terminal = initial_terminal_check\n",
    "\n",
    "            while not is_sim_terminal:\n",
    "                valid_moves = get_valid_locations(simulation_board)\n",
    "                if not valid_moves:\n",
    "                    is_sim_terminal = True; break\n",
    "\n",
    "                board_for_q_eval = None\n",
    "                if sim_player == PLAYER1_PIECE:\n",
    "                    board_for_q_eval = simulation_board\n",
    "                else:\n",
    "                    board_for_q_eval = self.q_agent._flip_state(simulation_board)\n",
    "\n",
    "                chosen_move, _ = self.q_agent.choose_action(board_for_q_eval)\n",
    "\n",
    "                if chosen_move is None or chosen_move not in valid_moves:\n",
    "                    chosen_move = random.choice(valid_moves)\n",
    "\n",
    "                row = get_next_open_row(simulation_board, chosen_move)\n",
    "                if row is None:\n",
    "                     print(f\"Warning: Q-Sim chose invalid move {chosen_move} - row is None.\")\n",
    "                     is_sim_terminal = True; break\n",
    "\n",
    "                drop_piece(simulation_board, row, chosen_move, sim_player)\n",
    "                sim_player = PLAYER2_PIECE if sim_player == PLAYER1_PIECE else PLAYER1_PIECE\n",
    "\n",
    "                # Check terminal state *after* move\n",
    "                loop_terminal_check = is_terminal_node(simulation_board)\n",
    "                is_sim_terminal = loop_terminal_check\n",
    "\n",
    "        except Exception as sim_e:\n",
    "             print(f\"\\n!!! ERROR during simulation !!!\")\n",
    "             print(f\"Player whose turn it was: {sim_player}\")\n",
    "             print(f\"Board state where error occurred:\\n{simulation_board}\")\n",
    "             print(f\"Error details: {type(sim_e)} - {sim_e}\")\n",
    "\n",
    "             return -1 \n",
    "\n",
    "        # --- Determine simulation result ---\n",
    "        winner = None\n",
    "        last_player = PLAYER2_PIECE if sim_player == PLAYER1_PIECE else PLAYER1_PIECE\n",
    "\n",
    "\n",
    "        try:\n",
    "             final_win_check_result = winning_move(simulation_board, last_player)\n",
    "\n",
    "        except Exception as win_e:\n",
    "             print(f\"\\n!!! ERROR during final win check !!!\")\n",
    "             print(f\"Board state:\\n{simulation_board}\")\n",
    "             print(f\"Error details: {type(win_e)} - {win_e}\")\n",
    "             final_win_check_result = False # Assume no win on error\n",
    "\n",
    "        if final_win_check_result:\n",
    "            winner = last_player\n",
    "        elif not get_valid_locations(simulation_board): # Check draw only if no winner\n",
    "            pass\n",
    "\n",
    "        sim_result = 0 # Draw\n",
    "        if winner == self.player_id: sim_result = 1\n",
    "        elif winner == self.opponent_id: sim_result = -1\n",
    "        return sim_result\n",
    "\n",
    "\n",
    "    def get_move(self, board):\n",
    "        \"\"\" Determines the move using MCTS guided by Q-Agent simulations. \"\"\"\n",
    "        start_time = time.time()\n",
    "        root = MCTSNode(state=board.copy(), player_at_node=self.player_id)\n",
    "\n",
    "        valid_locations = get_valid_locations(board)\n",
    "\n",
    "\n",
    "        # --- Immediate Win/Loss Check ---\n",
    "        for col in valid_locations:\n",
    "             temp_board_win = board.copy()\n",
    "             row = get_next_open_row(temp_board_win, col)\n",
    "             if row is not None:\n",
    "                 drop_piece(temp_board_win, row, col, self.player_id)\n",
    "                 win_check_result = winning_move(temp_board_win, self.player_id)\n",
    "                 if win_check_result:\n",
    "                     print(f\"Hybrid Player {self.player_id}: Found immediate winning move {col}\")\n",
    "                     return col\n",
    "\n",
    "        for col in valid_locations:\n",
    "             temp_board_loss = board.copy()\n",
    "             row = get_next_open_row(temp_board_loss, col)\n",
    "             if row is not None:\n",
    "                 drop_piece(temp_board_loss, row, col, self.opponent_id)\n",
    "                 block_check_result = winning_move(temp_board_loss, self.opponent_id)\n",
    "                 if block_check_result:\n",
    "                     print(f\"Hybrid Player {self.player_id}: Found immediate block at {col}\")\n",
    "                     return col\n",
    "\n",
    "\n",
    "        # --- MCTS Main Loop ---\n",
    "        for i in range(self.n_iterations):\n",
    "            node = root\n",
    "            current_board_state = board.copy()\n",
    "\n",
    "            # 1. Selection\n",
    "            while not node.untried_moves and node.children:\n",
    "                node = node.uct_select_child(self.exploration_constant)\n",
    "                if node is None: break\n",
    "                row = get_next_open_row(current_board_state, node.move)\n",
    "                if row is None: break\n",
    "                drop_piece(current_board_state, row, node.move, node.parent.player_at_node)\n",
    "            if node is None: continue\n",
    "\n",
    "            # 2. Expansion\n",
    "            try:\n",
    "                 node_is_terminal = is_terminal_node(node.state)\n",
    "            except Exception as e_debug:\n",
    "                 print(f\"DEBUG (Hybrid P{self.player_id}): Iter {i}, ERROR checking node terminal: {e_debug}\")\n",
    "                 node_is_terminal = True # Assume terminal on error\n",
    "\n",
    "            # --- The potentially problematic line ---\n",
    "            if node.untried_moves and not node_is_terminal:\n",
    "                move = random.choice(node.untried_moves)\n",
    "                current_player = node.player_at_node\n",
    "                next_player = self.opponent_id if current_player == self.player_id else self.player_id\n",
    "                row = get_next_open_row(current_board_state, move)\n",
    "                if row is not None:\n",
    "                    board_after_expansion = current_board_state.copy() # Copy state *before* dropping piece for the child node\n",
    "                    drop_piece(board_after_expansion, row, move, current_player)\n",
    "                    node = node.add_child(move, board_after_expansion, next_player) # Child node gets the state *after* the move\n",
    "                    # Update current_board_state to reflect the expansion for the simulation start\n",
    "                    current_board_state = board_after_expansion\n",
    "                else:\n",
    "                    node.untried_moves.remove(move); continue\n",
    "\n",
    "\n",
    "            # 3. Simulation (using Q-Agent)\n",
    "            simulation_result = self._simulate_with_q_agent(current_board_state, node.player_at_node)\n",
    "\n",
    "            # 4. Backpropagation\n",
    "            temp_node = node\n",
    "            while temp_node is not None:\n",
    "                 result_for_node = simulation_result if temp_node.player_at_node == self.player_id else -simulation_result\n",
    "                 temp_node.update(result_for_node)\n",
    "                 temp_node = temp_node.parent\n",
    "\n",
    "\n",
    "        # --- Choose Best Move ---\n",
    "        if not root.children:\n",
    "             print(f\"Hybrid Player {self.player_id}: Warning - No moves explored. Choosing random.\")\n",
    "             valid_fallback = get_valid_locations(board)\n",
    "             return random.choice(valid_fallback) if valid_fallback else None\n",
    "\n",
    "        best_child = max(root.children, key=lambda c: c.visits)\n",
    "        best_move = best_child.move\n",
    "        end_time = time.time()\n",
    "\n",
    "        parent_win_rate_for_best_child = (-best_child.score / best_child.visits) if best_child.visits > 0 else 0.0\n",
    "        win_rate_display = (parent_win_rate_for_best_child + 1) / 2 * 100\n",
    "\n",
    "        print(f\"Hybrid Player {self.player_id}: Chose column {best_move} \"\n",
    "              f\"({best_child.visits} visits, ~WinRate: {win_rate_display:.1f}%, \"\n",
    "              f\"Time: {end_time - start_time:.2f}s)\")\n",
    "\n",
    "        if best_move not in get_valid_locations(board):\n",
    "             print(f\"Hybrid Warning: Chosen best move {best_move} is invalid! Fallback.\")\n",
    "             valid_fallback = get_valid_locations(board)\n",
    "             return random.choice(valid_fallback) if valid_fallback else None\n",
    "\n",
    "        return best_move\n",
    "\n",
    "print(\"MCTS_QAgent_Hybrid class defined (with debugging).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5830aa9-914f-4d99-a365-47c910bee911",
   "metadata": {},
   "source": [
    "## THE GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53884fd1-cc93-48c3-b872-f8e56f84e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Runner Function `play_connect4` Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Game Runner\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def play_connect4(player1: Player, player2: Player):\n",
    "    \"\"\"\n",
    "    Runs a game of Connect 4 between two players.\n",
    "\n",
    "    Args:\n",
    "        player1 (Player): The player object for Player 1.\n",
    "        player2 (Player): The player object for Player 2.\n",
    "    \"\"\"\n",
    "    board = create_board()\n",
    "    game_over = False\n",
    "    turn = 0 # 0 for Player 1, 1 for Player 2\n",
    "\n",
    "    print(\"--- Starting Connect 4 Game ---\")\n",
    "    print(f\"Player 1 ({type(player1).__name__}) vs Player 2 ({type(player2).__name__})\")\n",
    "    print_board(board)\n",
    "\n",
    "    while not game_over:\n",
    "        current_player_obj = player1 if turn == 0 else player2\n",
    "        player_piece = PLAYER1_PIECE if turn == 0 else PLAYER2_PIECE\n",
    "\n",
    "        # Get move from the current player\n",
    "        try:\n",
    "            col = current_player_obj.get_move(board.copy()) # Pass a copy to prevent AI from cheating\n",
    "\n",
    "            if is_valid_location(board, col):\n",
    "                row = get_next_open_row(board, col)\n",
    "                drop_piece(board, row, col, player_piece)\n",
    "\n",
    "                print(\"-\" * 20)\n",
    "                print(f\"Player {player_piece} placed piece in column {col}\")\n",
    "                print_board(board)\n",
    "\n",
    "                if winning_move(board, player_piece):\n",
    "                    print(f\"\\n!!! Player {player_piece} ({type(current_player_obj).__name__}) wins! !!!\")\n",
    "                    game_over = True\n",
    "\n",
    "                elif len(get_valid_locations(board)) == 0:\n",
    "                    print(\"\\n!!! Game Over: It's a DRAW! !!!\")\n",
    "                    game_over = True\n",
    "                else:\n",
    "                    turn = 1 - turn # Switch turn\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(f\"!! Internal Error: Player {player_piece} chose invalid column {col}. Skipping turn. !!\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n!! An error occurred during Player {player_piece}'s turn: {e} !!\")\n",
    "            print(\"Game cannot continue.\")\n",
    "            game_over = True\n",
    "\n",
    "    print(\"--- Game Finished ---\")\n",
    "\n",
    "print(\"Game Runner Function `play_connect4` Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49ca7a-2047-4b27-9476-796fc4f33307",
   "metadata": {},
   "source": [
    "## Human vs Human Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26341dba-7cbc-4c6f-8eb4-860e7510c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (HumanPlayer) vs Player 2 (HumanPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (0, 1, 2, 3, 4, 5, 6):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Human vs Human Game\n",
    "\n",
    "# Make sure classes/functions are loaded from previous cells\n",
    "\n",
    "# Ensure Player classes are instantiated with correct IDs\n",
    "human1 = HumanPlayer(PLAYER1_PIECE)\n",
    "human2 = HumanPlayer(PLAYER2_PIECE)\n",
    "\n",
    "play_connect4(human1, human2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6545f-f146-4b56-874c-2535f6602001",
   "metadata": {},
   "source": [
    "## Human vs CNN-Minimax AI Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce170d68-3771-4995-8b53-fb81a13fbc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model loaded successfully from connect4_cnn_model.h5 for Player 2\n",
      "Model ready.\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (HumanPlayer) vs Player 2 (CNNMinimaxPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 1 (Score: 1.00, Time: 19.52s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   O   X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Please enter a number.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|   O   X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 2 (Score: 1.00, Time: 33.86s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|   O O X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "| X O O X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 4 (Score: 1.00, Time: 51.40s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Blocking opponent win in column 3\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       X       |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "| X     X       |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 1 (Score: 1.00, Time: 27.66s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "| X O   X       |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "| X O   X X     |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 1 (Score: 0.99, Time: 20.14s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|   O   X       |\n",
      "| X O   X X     |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O   X X     |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 1 (Score: 0.98, Time: 28.74s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|   O           |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O   X X     |\n",
      "| X O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|   O           |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O   X X     |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 2 (Score: 1.00, Time: 40.87s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|   O           |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O O X X     |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "|   O           |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O O X X     |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Running Minimax (depth 4)...\n",
      "AI Player 2: Chose column 3 (Score: 0.99, Time: 35.52s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|   O   O       |\n",
      "|   X   O       |\n",
      "|   O   X       |\n",
      "| X O O X X     |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|   O   O       |\n",
      "|   X   O       |\n",
      "| X O   X       |\n",
      "| X O O X X     |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Blocking opponent win in column 0\n",
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O       |\n",
      "| X O   X       |\n",
      "| X O O X X     |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O       |\n",
      "| X O   X       |\n",
      "| X O O X X X   |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Blocking opponent win in column 6\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O       |\n",
      "| X O   X       |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O       |\n",
      "| X O   X   X   |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Blocking opponent win in column 5\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O   O   |\n",
      "| X O   X   X   |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O   O   |\n",
      "| X O   X   X X |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "AI Player 2: Blocking opponent win in column 4\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O   O   |\n",
      "| X O   X O X X |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "|   O   O       |\n",
      "| O X   O   O X |\n",
      "| X O   X O X X |\n",
      "| X O O X X X O |\n",
      "| X O O X O X X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 1 (HumanPlayer) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "cnn_model_file = 'connect4_cnn_model.h5'\n",
    "ai_search_depth = 4 # Adjust as needed (higher = slower but potentially stronger)\n",
    "\n",
    "# --- Create Players ---\n",
    "human_player = HumanPlayer(PLAYER1_PIECE) # Human plays as Player 1\n",
    "try:\n",
    "    # AI plays as Player 2\n",
    "    cnn_ai_player = CNNMinimaxPlayer(PLAYER2_PIECE, model_path=cnn_model_file, search_depth=ai_search_depth)\n",
    "\n",
    "    # --- Start Game ---\n",
    "    if cnn_ai_player.model is not None: # Only play if model loaded correctly\n",
    "         play_connect4(human_player, cnn_ai_player)\n",
    "    else:\n",
    "        print(\"Cannot start game: CNN AI model failed to load.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: Make sure CNNMinimaxPlayer class is defined (run Cell 4).\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred setting up the Human vs AI game: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83e5c6-797d-4d74-ac35-a5b1e87280ef",
   "metadata": {},
   "source": [
    "## Random AI vs Random AI Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd9ef219-0e00-4ebd-81ee-a4728783881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Random AI vs Random AI Game ---\n",
      "SlightlyBetterRandomAIPlayer initialized for Player 2 (Opponent: 1)\n",
      "Starting game: RandomAIPlayer (P1) vs SlightlyBetterRandomAIPlayer (P2)\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (RandomAIPlayer) vs Player 2 (SlightlyBetterRandomAIPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 1\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X           |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X     O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 0\n",
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X X     O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| O             |\n",
      "| X X     O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 3\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| O             |\n",
      "| X X   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| O             |\n",
      "| X X O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 0\n",
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O             |\n",
      "| X X O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O           |\n",
      "| X X O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 3\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X O X O O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 4\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X X     |\n",
      "| X X O X O O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O O X X     |\n",
      "| X X O X O O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 5\n",
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X             |\n",
      "| O O O X X X   |\n",
      "| X X O X O O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X     O       |\n",
      "| O O O X X X   |\n",
      "| X X O X O O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 6\n",
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X     O       |\n",
      "| O O O X X X   |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X     O       |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 1\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "| X X   O       |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|               |\n",
      "|               |\n",
      "| O             |\n",
      "| X X   O       |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 3\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "| O     X       |\n",
      "| X X   O       |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "| O     X       |\n",
      "| X X   O O     |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 0\n",
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "| X             |\n",
      "| O     X       |\n",
      "| X X   O O     |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X   O O     |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 6\n",
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X   O O   X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X   O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 2\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X       |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X     O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 4\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "| X             |\n",
      "| O O   X X   O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "| X       O     |\n",
      "| O O   X X   O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 5\n",
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "| X       O     |\n",
      "| O O   X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "| X       O     |\n",
      "| O O O X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 4\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|         X     |\n",
      "| X       O     |\n",
      "| O O O X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|         X     |\n",
      "| X O     O     |\n",
      "| O O O X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Random AI Player 1: Chose column 2\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|         X     |\n",
      "| X O X   O     |\n",
      "| O O O X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "| O       X     |\n",
      "| X O X   O     |\n",
      "| O O O X X X O |\n",
      "| X X X O O O X |\n",
      "| O O O X X X O |\n",
      "| X X O X O O X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 2 (SlightlyBetterRandomAIPlayer) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Setting up Random AI vs Random AI Game ---\")\n",
    "\n",
    "try:\n",
    "    # --- Create Players ---\n",
    "    # Create an instance of RandomAIPlayer for Player 1\n",
    "    random_ai_1 = RandomAIPlayer(PLAYER1_PIECE)\n",
    "\n",
    "    # Create another instance of RandomAIPlayer for Player 2\n",
    "    random_ai_2 = SlightlyBetterRandomAIPlayer(PLAYER2_PIECE)\n",
    "\n",
    "    # --- Start Game ---\n",
    "    print(f\"Starting game: {type(random_ai_1).__name__} (P1) vs {type(random_ai_2).__name__} (P2)\")\n",
    "    play_connect4(random_ai_1, random_ai_2)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: A required class or function is not defined: {e}\")\n",
    "     print(\"Please ensure Cells 1, 5, and 6 have been executed successfully.\")\n",
    "except Exception as e:\n",
    "     print(f\"An unexpected error occurred setting up the Random AI vs Random AI game: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1e007-39aa-41a1-80d3-bd678bf2bc56",
   "metadata": {},
   "source": [
    "## Human vs MCTS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f95846a3-bb38-4f92-95ac-a862161cce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Human vs MCTS AI Game ---\n",
      "Human player created as Player 1\n",
      "MCTSPlayer initialized for Player 2 (2000 iterations/move, Heuristic Playouts, Corrected UCT)\n",
      "MCTS AI player created as Player 2 with 2000 iterations.\n",
      "\n",
      "Starting game...\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (HumanPlayer) vs Player 2 (MCTSPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 1 (529 visits, ~WinRate: 49.1%, Time: 47.87s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   O X         |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X           |\n",
      "|   O X         |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 2 (461 visits, ~WinRate: 43.8%, Time: 43.24s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X O         |\n",
      "|   O X         |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X O         |\n",
      "|   O X X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 4 (610 visits, ~WinRate: 50.5%, Time: 35.59s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X O         |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|   X O   X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 2 (1529 visits, ~WinRate: 62.7%, Time: 23.64s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|     O         |\n",
      "|   X O   X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "|     O         |\n",
      "|   X O   X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 4 (551 visits, ~WinRate: 54.9%, Time: 18.47s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "|     O   O     |\n",
      "|   X O   X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "|     O   O     |\n",
      "|   X O X X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 3 (1939 visits, ~WinRate: 93.1%, Time: 4.82s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "|     O O O     |\n",
      "|   X O X X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|     X         |\n",
      "|   X O O O     |\n",
      "|   X O X X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Found immediate winning move 4\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|     X   O     |\n",
      "|   X O O O     |\n",
      "|   X O X X     |\n",
      "|   O X X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 2 (MCTSPlayer) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "print(\"\\n--- Setting up Human vs MCTS AI Game ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Adjust the number of iterations for MCTS. Higher values mean stronger AI but slower moves.\n",
    "mcts_iterations = 2000  \n",
    "\n",
    "# Choose who plays first (PLAYER1_PIECE goes first)\n",
    "human_player_id = PLAYER1_PIECE\n",
    "mcts_player_id = PLAYER2_PIECE\n",
    "\n",
    "\n",
    "# --- Create Players ---\n",
    "try:\n",
    "    # Create the Human player instance\n",
    "    human_player = HumanPlayer(human_player_id)\n",
    "    print(f\"Human player created as Player {human_player_id}\")\n",
    "\n",
    "    # Create the MCTS AI player instance\n",
    "    mcts_ai_opponent = MCTSPlayer(player_id=mcts_player_id, iterations=mcts_iterations)\n",
    "    print(f\"MCTS AI player created as Player {mcts_player_id} with {mcts_iterations} iterations.\")\n",
    "\n",
    "    # --- Start Game ---\n",
    "    print(\"\\nStarting game...\")\n",
    "    # Determine the order based on assigned IDs\n",
    "    if human_player_id == PLAYER1_PIECE:\n",
    "        play_connect4(human_player, mcts_ai_opponent)\n",
    "    else:\n",
    "        play_connect4(mcts_ai_opponent, human_player)\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"\\nError: A required class or function is not defined: {e}\")\n",
    "     print(\"Please ensure Cells 1, 2, 6, and 14 have been executed successfully.\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nAn unexpected error occurred setting up the Human vs MCTS game: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c42c3b-b9b2-44c2-aefd-fef9bc2d4571",
   "metadata": {},
   "source": [
    "## Q-Agent vs MCTS Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b9f11bb4-7d6c-4387-bb8d-e2c74063b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Q-Agent (P1) vs MCTS Player (P2) Game ---\n",
      "Loading Q-Agent for Player 1 from 'connect4_q_agent_selfplay_gen2.pkl'...\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "Q-Agent (P1) initialized in evaluation mode.\n",
      "\n",
      "Initializing MCTS Player for Player 2 (2000 iterations)...\n",
      "MCTSPlayer initialized for Player 2 (2000 iterations/move, Heuristic Playouts, Corrected UCT)\n",
      "MCTS Player (P2) initialized.\n",
      "\n",
      "Starting game: Q-Agent (P1) vs MCTS Player (P2)\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (QLearningAgent) vs Player 2 (MCTSPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 3 (478 visits, ~WinRate: 43.8%, Time: 47.50s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 5 (965 visits, ~WinRate: 44.6%, Time: 30.58s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 5 (582 visits, ~WinRate: 45.2%, Time: 27.72s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O   O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O   O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 4 (1032 visits, ~WinRate: 50.9%, Time: 12.84s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O O O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X X     |\n",
      "|       O O O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 5 (1287 visits, ~WinRate: 68.0%, Time: 10.10s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X X O   |\n",
      "|       O O O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|       X X     |\n",
      "|       X X O   |\n",
      "|       O O O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Found immediate winning move 5\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|       X X O   |\n",
      "|       X X O   |\n",
      "|       O O O   |\n",
      "|       X X O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 2 (MCTSPlayer) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "print(\"\\n--- Setting up Q-Agent (P1) vs MCTS Player (P2) Game ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure this matches the file saved during Q-agent training\n",
    "Q_TABLE_FILE = \"connect4_q_agent_selfplay_gen2.pkl\"\n",
    "\n",
    "# Adjust the number of iterations for MCTS. Higher values mean stronger AI but slower moves.\n",
    "MCTS_ITERATIONS = 2000  \n",
    "\n",
    "# --- Initialize Players ---\n",
    "q_agent_player1 = None\n",
    "mcts_player2 = None\n",
    "players_ready = True\n",
    "\n",
    "# 1. Initialize Q-Learning Agent (Player 1)\n",
    "try:\n",
    "    print(f\"Loading Q-Agent for Player 1 from '{Q_TABLE_FILE}'...\")\n",
    "    q_agent_player1 = QLearningAgent(player_id=PLAYER1_PIECE) # Trained as P1, playing as P1\n",
    "\n",
    "    # Load the trained Q-table\n",
    "    q_agent_player1.load_q_table(Q_TABLE_FILE)\n",
    "\n",
    "    # Check if loading was successful or table is empty\n",
    "    if not q_agent_player1.q_table:\n",
    "        print(f\"WARNING: Q-table file '{Q_TABLE_FILE}' not found or loaded empty.\")\n",
    "        print(\"Q-Agent will likely perform poorly (randomly or based on heuristics only).\")\n",
    "        # players_ready = False # Optional: Decide if you want to stop if Q-table is bad\n",
    "\n",
    "    # Set agent to evaluation mode (no exploration, no learning)\n",
    "    q_agent_player1.is_learning = False\n",
    "    q_agent_player1.epsilon = 0.0\n",
    "    print(\"Q-Agent (P1) initialized in evaluation mode.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: 'QLearningAgent' class not defined.\")\n",
    "    print(\"Please ensure the cell containing the QLearningAgent class definition (e.g., Cell 16) has been executed.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Q-table file '{Q_TABLE_FILE}' not found.\")\n",
    "    print(\"Cannot run game without the trained Q-table.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Q-Agent: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "# 2. Initialize MCTS Player (Player 2)\n",
    "if players_ready: # Only proceed if Q-agent setup was okay (or warning ignored)\n",
    "    try:\n",
    "        print(f\"\\nInitializing MCTS Player for Player 2 ({MCTS_ITERATIONS} iterations)...\")\n",
    "        mcts_player2 = MCTSPlayer(player_id=PLAYER2_PIECE, iterations=MCTS_ITERATIONS)\n",
    "        print(\"MCTS Player (P2) initialized.\")\n",
    "\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: 'MCTSPlayer' class not defined.\")\n",
    "        print(\"Please ensure the cell containing the MCTSPlayer class definition (e.g., Cell 14 - corrected version) has been executed.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the MCTS Player: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "# --- Run Game ---\n",
    "if players_ready and q_agent_player1 and mcts_player2:\n",
    "    try:\n",
    "        print(\"\\nStarting game: Q-Agent (P1) vs MCTS Player (P2)\")\n",
    "        play_connect4(q_agent_player1, mcts_player2)\n",
    "    except NameError:\n",
    "         print(\"\\nERROR: 'play_connect4' function not defined.\")\n",
    "         print(\"Please ensure the cell containing the play_connect4 function (e.g., Cell 6) has been executed.\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nAn unexpected error occurred during the game: {e}\")\n",
    "else:\n",
    "    print(\"\\nGame setup failed. Cannot start the match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34240b-0587-4684-b08e-bb4953e38cb8",
   "metadata": {},
   "source": [
    "## New Q-Agent (Self-Play) vs Original Q-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cd0fb541-406d-4908-b695-ae6911a468af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up New Q-Agent (Self-Play) vs Original Q-Agent Game ---\n",
      "\n",
      "Loading Newer Q-Agent (1) policy from: connect4_q_agent_selfplay_gen2.pkl\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "Newer Q-Agent (P1) initialized in evaluation mode (VERBOSE).\n",
      "\n",
      "Loading Original Q-Agent (2) policy from: connect4_q_agent_heuristic.pkl\n",
      "Q-table loaded successfully from connect4_q_agent_heuristic.pkl (307021 entries)\n",
      "Original Q-Agent (P2) initialized in evaluation mode (VERBOSE).\n",
      "NOTE: Agent P2 will use state-flipping as it's playing as P2.\n",
      "\n",
      "Starting game: New Q-Agent vs Original Q-Agent\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (QLearningAgent) vs Player 2 (QLearningAgent)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 1: Chose column 3 (Exploit, ChosenQ: 1.4666, MaxQ: 1.4666, Time: 0.000s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 2: Chose column 3 (Exploit(TIEBREAK), ChosenQ: 0.0000, MaxQ: 0.0000, Time: 0.000s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 1: Chose column 2 (Exploit(TIEBREAK), ChosenQ: 2.7510, MaxQ: 2.7510, Time: 0.000s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|     X X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 2: Chose column 3 (Exploit(TIEBREAK), ChosenQ: 0.0000, MaxQ: 0.0000, Time: 0.000s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|     X X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 1: Chose column 4 (Exploit, ChosenQ: 5.2342, MaxQ: 5.2342, Time: 0.000s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|     X X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 2: Chose column 3 (Exploit(TIEBREAK), ChosenQ: 0.0000, MaxQ: 0.0000, Time: 0.000s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|     X X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Q-Agent 1: Chose column 1 (Exploit(TIEBREAK), ChosenQ: 10.0000, MaxQ: 10.0000, Time: 0.000s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|       O       |\n",
      "|   X X X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 1 (QLearningAgent) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "print(\"\\n--- Setting up New Q-Agent (Self-Play) vs Original Q-Agent Game ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# File for the agent trained via self-play\n",
    "NEW_Q_TABLE_FILE = \"connect4_q_agent_selfplay_gen2.pkl\"\n",
    "# File for the original agent\n",
    "ORIGINAL_Q_TABLE_FILE = \"connect4_q_agent_heuristic.pkl\"\n",
    "\n",
    "# Assign Player IDs\n",
    "# Let's have the newer agent play as P1 and the original as P2\n",
    "NEW_AGENT_PLAYER_ID = PLAYER1_PIECE\n",
    "ORIGINAL_AGENT_PLAYER_ID = PLAYER2_PIECE\n",
    "\n",
    "# --- Initialize Players ---\n",
    "q_agent_new = None      # Agent from self-play\n",
    "q_agent_original = None # Agent from first training round\n",
    "players_ready = True\n",
    "\n",
    "# 1. Initialize Newer Agent (e.g., Player 1)\n",
    "try:\n",
    "    print(f\"\\nLoading Newer Q-Agent ({NEW_AGENT_PLAYER_ID}) policy from: {NEW_Q_TABLE_FILE}\")\n",
    "    q_agent_new = QLearningAgent(player_id=NEW_AGENT_PLAYER_ID)\n",
    "\n",
    "    q_agent_new.load_q_table(NEW_Q_TABLE_FILE)\n",
    "    if not q_agent_new.q_table:\n",
    "        print(f\"WARNING: Newer Q-table file '{NEW_Q_TABLE_FILE}' not found or loaded empty.\")\n",
    "        players_ready = False # Stop if the agent we want to test is missing\n",
    "\n",
    "    # Set to EVALUATION mode and VERBOSE\n",
    "    q_agent_new.is_learning = False\n",
    "    q_agent_new.epsilon = 0.0\n",
    "    q_agent_new.verbose = True\n",
    "    print(f\"Newer Q-Agent (P{NEW_AGENT_PLAYER_ID}) initialized in evaluation mode (VERBOSE).\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: 'QLearningAgent' class not defined.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Newer Q-table file '{NEW_Q_TABLE_FILE}' not found.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Newer Q-Agent: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "\n",
    "# 2. Initialize Original Agent (e.g., Player 2)\n",
    "if players_ready:\n",
    "    try:\n",
    "        print(f\"\\nLoading Original Q-Agent ({ORIGINAL_AGENT_PLAYER_ID}) policy from: {ORIGINAL_Q_TABLE_FILE}\")\n",
    "        # *** Assign the PLAYER 2 ID here ***\n",
    "        q_agent_original = QLearningAgent(player_id=ORIGINAL_AGENT_PLAYER_ID)\n",
    "\n",
    "        q_agent_original.load_q_table(ORIGINAL_Q_TABLE_FILE)\n",
    "        if not q_agent_original.q_table:\n",
    "            print(f\"WARNING: Original Q-table file '{ORIGINAL_Q_TABLE_FILE}' not found or loaded empty.\")\n",
    "            players_ready = False # Stop if the opponent is missing\n",
    "\n",
    "        # Set to EVALUATION mode and VERBOSE\n",
    "        q_agent_original.is_learning = False\n",
    "        q_agent_original.epsilon = 0.0\n",
    "        q_agent_original.verbose = True # <<< Enable detailed printing for this agent too\n",
    "        print(f\"Original Q-Agent (P{ORIGINAL_AGENT_PLAYER_ID}) initialized in evaluation mode (VERBOSE).\")\n",
    "        print(f\"NOTE: Agent P{ORIGINAL_AGENT_PLAYER_ID} will use state-flipping as it's playing as P2.\")\n",
    "\n",
    "\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: 'QLearningAgent' class not defined.\")\n",
    "        players_ready = False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nERROR: Original Q-table file '{ORIGINAL_Q_TABLE_FILE}' not found.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the Original Q-Agent: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "\n",
    "# --- Run Game ---\n",
    "if players_ready and q_agent_new and q_agent_original:\n",
    "    try:\n",
    "        print(\"\\nStarting game: New Q-Agent vs Original Q-Agent\")\n",
    "        # Ensure the player order matches the assigned IDs\n",
    "        if NEW_AGENT_PLAYER_ID == PLAYER1_PIECE:\n",
    "            play_connect4(q_agent_new, q_agent_original)\n",
    "        else:\n",
    "            play_connect4(q_agent_original, q_agent_new) # Should not happen with current assignment\n",
    "\n",
    "    except NameError:\n",
    "         print(\"\\nERROR: 'play_connect4' function not defined.\")\n",
    "         print(\"Please ensure the cell containing the play_connect4 function (e.g., Cell 6) has been executed.\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nAn unexpected error occurred during the game: {e}\")\n",
    "else:\n",
    "    print(\"\\nGame setup failed. Cannot start the match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724328-bbe4-4ce5-9520-3776ed31343d",
   "metadata": {},
   "source": [
    "## Human vs Q-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f3f66a3c-b31d-4ed3-9c33-d134f5eff8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Trained Q-Agent ---\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (QLearningAgent) vs Player 2 (HumanPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 4, 5, 6, 7):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Please enter a number.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 4, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 5, 6, 7):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|       O       |\n",
      "|       X       |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|       O       |\n",
      "|     O X       |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|       O       |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 3, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|     O O       |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "|     O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X     |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "|     O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O     |\n",
      "| O   O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "|     X X O   X |\n",
      "| O   O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "|     X O X     |\n",
      "| O   X X O   X |\n",
      "| O   O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "| X   X O X     |\n",
      "| O   X X O   X |\n",
      "| O   O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "| X   X O X   O |\n",
      "| O   X X O   X |\n",
      "| O   O O X   X |\n",
      "| O   O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "| X   X O X   O |\n",
      "| O   X X O   X |\n",
      "| O   O O X   X |\n",
      "| O X O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 2, choose column (1, 2, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|     O O X     |\n",
      "|     O X X     |\n",
      "| X   X O X   O |\n",
      "| O   X X O   X |\n",
      "| O O O O X   X |\n",
      "| O X O X X   O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 2 (HumanPlayer) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Trained Q-Agent ---\")\n",
    "try:\n",
    "    # Load the trained agent\n",
    "    trained_q_agent = QLearningAgent(player_id=PLAYER1_PIECE) # Or PLAYER2_PIECE if trained as P2\n",
    "    trained_q_agent.load_q_table(\"connect4_q_agent_selfplay_gen2.pkl\")\n",
    "    trained_q_agent.is_learning = False # Ensure it's not learning\n",
    "    trained_q_agent.epsilon = 0.0       # Ensure it's not exploring\n",
    "\n",
    "    if not trained_q_agent.q_table:\n",
    "        print(\"Warning: Q-table is empty. Agent has not been trained or failed to load.\")\n",
    "    else:\n",
    "        # Play against human\n",
    "        human_opponent = HumanPlayer(PLAYER2_PIECE if trained_q_agent.player_id == PLAYER1_PIECE else PLAYER1_PIECE)\n",
    "        play_connect4(trained_q_agent, human_opponent)\n",
    "\n",
    "\n",
    "except NameError as e:\n",
    "     print(f\"Error: A required class or function is not defined: {e}\")\n",
    "     print(\"Please ensure relevant cells (1, 2, 6, 16) are executed.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Cannot evaluate. Trained Q-table file 'connect4_q_agent_heuristic.pkl' not found.\")\n",
    "except Exception as e:\n",
    "     print(f\"An unexpected error occurred during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd843abd-76e7-4aa1-9e6b-9a7081afeb30",
   "metadata": {},
   "source": [
    "## Hybrid MCTS+QAgent vs Standard MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a187f0bb-33ff-48b2-9918-7751eb92a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Hybrid MCTS+QAgent vs Standard MCTS Game ---\n",
      "\n",
      "Initializing Hybrid Player (1) with 2000 iterations...\n",
      "Initializing Hybrid Agent (Player 1)\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "Internal Q-Agent loaded (24526 entries) for Hybrid Player 1.\n",
      "Hybrid Player initialized.\n",
      "\n",
      "Initializing Standard MCTS Player (2) with 2000 iterations...\n",
      "MCTSPlayer initialized for Player 2 (2000 iterations/move, Heuristic Playouts, Corrected UCT)\n",
      "Standard MCTS Player initialized.\n",
      "\n",
      "Starting game: Hybrid MCTS+QAgent vs Standard MCTS\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (MCTS_QAgent_Hybrid) vs Player 2 (MCTSPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 3 (1164 visits, ~WinRate: 63.5%, Time: 10.98s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 4 (692 visits, ~WinRate: 44.8%, Time: 49.32s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 4 (640 visits, ~WinRate: 63.8%, Time: 8.61s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 4 (907 visits, ~WinRate: 43.9%, Time: 35.21s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|         O     |\n",
      "|         X     |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 4 (1296 visits, ~WinRate: 62.7%, Time: 6.45s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "|         O     |\n",
      "|         X     |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 3 (688 visits, ~WinRate: 44.3%, Time: 29.57s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "|         O     |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 3 (1456 visits, ~WinRate: 60.2%, Time: 5.68s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 1 (795 visits, ~WinRate: 36.5%, Time: 25.01s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|         X     |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 3 (681 visits, ~WinRate: 61.0%, Time: 5.05s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 3 (758 visits, ~WinRate: 35.1%, Time: 20.17s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 1 (1226 visits, ~WinRate: 64.4%, Time: 4.35s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 2 (443 visits, ~WinRate: 29.3%, Time: 16.70s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O O X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 5 (859 visits, ~WinRate: 75.6%, Time: 2.22s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 5 (498 visits, ~WinRate: 26.5%, Time: 8.28s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|   X   O X O   |\n",
      "|   O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 0 (868 visits, ~WinRate: 79.0%, Time: 1.63s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|       X O     |\n",
      "|   X   O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 1 (565 visits, ~WinRate: 28.1%, Time: 5.28s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|       O       |\n",
      "|       X X     |\n",
      "|   O   X O     |\n",
      "|   X   O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 1 (1208 visits, ~WinRate: 87.7%, Time: 1.30s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|       O       |\n",
      "|   X   X X     |\n",
      "|   O   X O     |\n",
      "|   X   O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Chose column 0 (417 visits, ~WinRate: 24.5%, Time: 4.67s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 0\n",
      "|               |\n",
      "|       O       |\n",
      "|   X   X X     |\n",
      "|   O   X O     |\n",
      "| O X   O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Chose column 2 (601 visits, ~WinRate: 90.3%, Time: 1.14s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|       O       |\n",
      "|   X   X X     |\n",
      "|   O   X O     |\n",
      "| O X X O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "MCTS Player 2: Found immediate block at 2\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|       O       |\n",
      "|   X   X X     |\n",
      "|   O O X O     |\n",
      "| O X X O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 1: Found immediate winning move 2\n",
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|       O       |\n",
      "|   X X X X     |\n",
      "|   O O X O     |\n",
      "| O X X O X O   |\n",
      "| X O O X O X   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 1 (MCTS_QAgent_Hybrid) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n--- Setting up Hybrid MCTS+QAgent vs Standard MCTS Game ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Q-table for the Hybrid agent to use for simulations\n",
    "Q_TABLE_TO_USE = \"connect4_q_agent_selfplay_gen2.pkl\" # Likely your strongest Q-table\n",
    "\n",
    "# MCTS Iterations - You might need fewer for Hybrid due to smarter sims\n",
    "HYBRID_ITERATIONS = 2000       \n",
    "STANDARD_MCTS_ITERATIONS = 2000 \n",
    "\n",
    "# Assign Player IDs (Example: Hybrid = P1, Standard MCTS = P2)\n",
    "HYBRID_PLAYER_ID = PLAYER1_PIECE\n",
    "STANDARD_MCTS_PLAYER_ID = PLAYER2_PIECE\n",
    "\n",
    "# --- Initialize Players ---\n",
    "hybrid_player = None\n",
    "standard_mcts_player = None\n",
    "players_ready = True\n",
    "\n",
    "# 1. Initialize Hybrid Player\n",
    "try:\n",
    "    print(f\"\\nInitializing Hybrid Player ({HYBRID_PLAYER_ID}) with {HYBRID_ITERATIONS} iterations...\")\n",
    "    hybrid_player = MCTS_QAgent_Hybrid(\n",
    "        player_id=HYBRID_PLAYER_ID,\n",
    "        q_table_path=Q_TABLE_TO_USE,\n",
    "        iterations=HYBRID_ITERATIONS\n",
    "    )\n",
    "    print(\"Hybrid Player initialized.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\nERROR: Required class not defined ({e}).\")\n",
    "    print(\"Ensure MCTS_QAgent_Hybrid and potentially QLearningAgent/MCTSNode are defined.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Q-table file '{Q_TABLE_TO_USE}' not found for Hybrid Agent.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Hybrid Player: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "# 2. Initialize Standard MCTS Player\n",
    "if players_ready:\n",
    "    try:\n",
    "        print(f\"\\nInitializing Standard MCTS Player ({STANDARD_MCTS_PLAYER_ID}) with {STANDARD_MCTS_ITERATIONS} iterations...\")\n",
    "        standard_mcts_player = MCTSPlayer( # Use the standard MCTSPlayer class\n",
    "            player_id=STANDARD_MCTS_PLAYER_ID,\n",
    "            iterations=STANDARD_MCTS_ITERATIONS\n",
    "        )\n",
    "        print(\"Standard MCTS Player initialized.\")\n",
    "\n",
    "    except NameError as e:\n",
    "        print(f\"\\nERROR: MCTSPlayer class not defined ({e}).\")\n",
    "        print(\"Please ensure the cell containing the MCTSPlayer class definition (e.g., Cell 14 - corrected version) has been executed.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the Standard MCTS Player: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "\n",
    "# --- Run Game ---\n",
    "if players_ready and hybrid_player and standard_mcts_player:\n",
    "    try:\n",
    "        print(\"\\nStarting game: Hybrid MCTS+QAgent vs Standard MCTS\")\n",
    "        # Ensure the player order matches the assigned IDs\n",
    "        if HYBRID_PLAYER_ID == PLAYER1_PIECE:\n",
    "            play_connect4(hybrid_player, standard_mcts_player)\n",
    "        else:\n",
    "            play_connect4(standard_mcts_player, hybrid_player) # If Hybrid is P2\n",
    "\n",
    "    except NameError:\n",
    "         print(\"\\nERROR: 'play_connect4' function not defined.\")\n",
    "         print(\"Please ensure the cell containing the play_connect4 function (e.g., Cell 6) has been executed.\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nAn unexpected error occurred during the game: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nGame setup failed. Cannot start the match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a667a-73e6-448a-b8ee-d8a4b90e112c",
   "metadata": {},
   "source": [
    "## Hybrid MCTS+QAgent vs Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "050901fc-5be4-4093-bc90-f4302d127075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Human (P2) vs Hybrid MCTS+QAgent (P1) Game ---\n",
      "\n",
      "Initializing Hybrid Player (2) with 1500 iterations...\n",
      "Initializing Hybrid Agent (Player 2)\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "Internal Q-Agent loaded (24526 entries) for Hybrid Player 2.\n",
      "Hybrid Player initialized.\n",
      "\n",
      "Initializing Human Player (1)...\n",
      "Human Player initialized.\n",
      "\n",
      "Starting game: Hybrid MCTS+QAgent (P1) vs Human (P2)\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (MCTS_QAgent_Hybrid) vs Player 2 (HumanPlayer)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (499 visits, ~WinRate: 64.9%, Time: 7.80s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (545 visits, ~WinRate: 64.9%, Time: 6.56s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (903 visits, ~WinRate: 60.7%, Time: 5.82s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O   O   |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (517 visits, ~WinRate: 59.3%, Time: 4.41s)\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O   O   |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 5\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       X   O   |\n",
      "|       O   O   |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Found immediate winning move 5\n",
      "--------------------\n",
      "Player 1 placed piece in column 5\n",
      "|               |\n",
      "|       X       |\n",
      "|       X   X   |\n",
      "|       X   O   |\n",
      "|       O   O   |\n",
      "|       X   O   |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|               |\n",
      "|       X       |\n",
      "|       X   X   |\n",
      "|       X   O   |\n",
      "|       O   O   |\n",
      "|       X   O O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Found immediate block at 3\n",
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       X   X   |\n",
      "|       X   O   |\n",
      "|       O   O   |\n",
      "|       X   O O |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 1 (MCTS_QAgent_Hybrid) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "print(\"\\n--- Setting up Human (P2) vs Hybrid MCTS+QAgent (P1) Game ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Select the Q-table file the Hybrid agent should use\n",
    "Q_TABLE_TO_USE = \"connect4_q_agent_selfplay_gen2.pkl\" # Or \"connect4_q_agent_heuristic.pkl\"\n",
    "\n",
    "# Set the number of MCTS iterations for the Hybrid player\n",
    "HYBRID_ITERATIONS = 1500\n",
    "\n",
    "# Assign Player IDs\n",
    "HYBRID_PLAYER_ID = PLAYER1_PIECE \n",
    "HUMAN_PLAYER_ID = PLAYER2_PIECE  \n",
    "\n",
    "# --- Initialize Players ---\n",
    "hybrid_player = None\n",
    "human_player = None\n",
    "players_ready = True\n",
    "\n",
    "# 1. Initialize Hybrid Player (Player 1)\n",
    "try:\n",
    "    print(f\"\\nInitializing Hybrid Player ({HYBRID_PLAYER_ID}) with {HYBRID_ITERATIONS} iterations...\")\n",
    "    hybrid_player = MCTS_QAgent_Hybrid(\n",
    "        player_id=HYBRID_PLAYER_ID,\n",
    "        q_table_path=Q_TABLE_TO_USE,\n",
    "        iterations=HYBRID_ITERATIONS\n",
    "    )\n",
    "\n",
    "    print(\"Hybrid Player initialized.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\nERROR: Required class not defined ({e}).\")\n",
    "    print(\"Ensure MCTS_QAgent_Hybrid, QLearningAgent, MCTSNode classes are defined.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Q-table file '{Q_TABLE_TO_USE}' not found for Hybrid Agent.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Hybrid Player: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "# 2. Initialize Human Player (Player 2)\n",
    "if players_ready:\n",
    "    try:\n",
    "        print(f\"\\nInitializing Human Player ({HUMAN_PLAYER_ID})...\")\n",
    "        human_player = HumanPlayer(player_id=HUMAN_PLAYER_ID) # Assign P2\n",
    "        print(\"Human Player initialized.\")\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: HumanPlayer class not defined.\")\n",
    "        print(\"Please ensure the cell containing the HumanPlayer class definition (e.g., Cell 2) has been executed.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the Human Player: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "\n",
    "# --- Run Game ---\n",
    "if players_ready and hybrid_player and human_player:\n",
    "    try:\n",
    "        print(\"\\nStarting game: Hybrid MCTS+QAgent (P1) vs Human (P2)\")\n",
    "        # Player 1 (Hybrid) goes first, Player 2 (Human) goes second\n",
    "        play_connect4(hybrid_player, human_player)\n",
    "    except NameError:\n",
    "         print(\"\\nERROR: 'play_connect4' function not defined.\")\n",
    "         print(\"Please ensure the cell containing the play_connect4 function (e.g., Cell 6) has been executed.\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nAn unexpected error occurred during the game: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nGame setup failed. Cannot start the match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "54a12178-48af-4c0d-b6f1-20c6e5c29782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Setting up Human (P1) vs Hybrid MCTS+QAgent (P2) Game ---\n",
      "\n",
      "Initializing Hybrid Player (2) with 1500 iterations...\n",
      "Initializing Hybrid Agent (Player 2)\n",
      "Q-table loaded successfully from connect4_q_agent_selfplay_gen2.pkl (24526 entries)\n",
      "Internal Q-Agent loaded (24526 entries) for Hybrid Player 2.\n",
      "Hybrid Player initialized.\n",
      "\n",
      "Initializing Human Player (1)...\n",
      "Human Player initialized.\n",
      "\n",
      "Starting game: Human (P1) vs Hybrid MCTS+QAgent (P2)\n",
      "--- Starting Connect 4 Game ---\n",
      "Player 1 (HumanPlayer) vs Player 2 (MCTS_QAgent_Hybrid)\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 4 (686 visits, ~WinRate: 40.1%, Time: 7.20s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (1107 visits, ~WinRate: 40.2%, Time: 5.86s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|               |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 1 (535 visits, ~WinRate: 40.1%, Time: 6.26s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|               |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 3\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X       |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 4 (1106 visits, ~WinRate: 53.0%, Time: 4.13s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O       |\n",
      "|       X O     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|               |\n",
      "|       X       |\n",
      "|       X       |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 4 (804 visits, ~WinRate: 46.1%, Time: 3.91s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|   O   X O     |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|   O   X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 2 (423 visits, ~WinRate: 49.1%, Time: 2.90s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|     X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 1 (1013 visits, ~WinRate: 39.5%, Time: 3.03s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|       O X     |\n",
      "|   O X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|               |\n",
      "|       X       |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 4 (436 visits, ~WinRate: 33.0%, Time: 2.84s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 4\n",
      "|               |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 4, 5, 6, 7):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 4\n",
      "|         X     |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 3 (862 visits, ~WinRate: 35.8%, Time: 1.64s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 3\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O     |\n",
      "|   O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O     |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 6 (683 visits, ~WinRate: 29.0%, Time: 1.44s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X     |\n",
      "|   O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 6, 7):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 6\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O     |\n",
      "|   X   O X   X |\n",
      "|   O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 6 (713 visits, ~WinRate: 27.6%, Time: 1.45s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O   O |\n",
      "|   X   O X   X |\n",
      "|   O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 6, 7):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 0\n",
      "|       O X     |\n",
      "|       X O     |\n",
      "|       X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 6 (772 visits, ~WinRate: 22.2%, Time: 1.20s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|       O X     |\n",
      "|       X O   O |\n",
      "|       X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|       O X     |\n",
      "|       X O   O |\n",
      "|   X   X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 1 (690 visits, ~WinRate: 16.7%, Time: 0.65s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 1\n",
      "|       O X     |\n",
      "|   O   X O   O |\n",
      "|   X   X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 2, 3, 6, 7):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 1\n",
      "|   X   O X     |\n",
      "|   O   X O   O |\n",
      "|   X   X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Chose column 6 (538 visits, ~WinRate: 6.7%, Time: 0.39s)\n",
      "--------------------\n",
      "Player 2 placed piece in column 6\n",
      "|   X   O X   O |\n",
      "|   O   X O   O |\n",
      "|   X   X O   O |\n",
      "|   X   O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Player 1, choose column (1, 3, 6):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Player 1 placed piece in column 2\n",
      "|   X   O X   O |\n",
      "|   O   X O   O |\n",
      "|   X   X O   O |\n",
      "|   X X O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "Hybrid Player 2: Found immediate winning move 2\n",
      "--------------------\n",
      "Player 2 placed piece in column 2\n",
      "|   X   O X   O |\n",
      "|   O   X O   O |\n",
      "|   X O X O   O |\n",
      "|   X X O X   X |\n",
      "| X O X X O   O |\n",
      "| X O O X O   X |\n",
      "+---------------+\n",
      "  1 2 3 4 5 6 7\n",
      "\n",
      "!!! Player 2 (MCTS_QAgent_Hybrid) wins! !!!\n",
      "--- Game Finished ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "print(\"\\n--- Setting up Human (P1) vs Hybrid MCTS+QAgent (P2) Game ---\") \n",
    "\n",
    "# --- Configuration ---\\n\",\n",
    "\n",
    "Q_TABLE_TO_USE = \"connect4_q_agent_selfplay_gen2.pkl\" \n",
    "\n",
    "# Set the number of MCTS iterations for the Hybrid player\n",
    "HYBRID_ITERATIONS = 1500\n",
    "\n",
    "# Assign Player IDs (Human = P1, AI = P2)\n",
    "HUMAN_PLAYER_ID = PLAYER1_PIECE  \n",
    "HYBRID_PLAYER_ID = PLAYER2_PIECE \n",
    "\n",
    "# --- Initialize Players ---\n",
    "hybrid_player = None\n",
    "human_player = None\n",
    "players_ready = True\n",
    "\n",
    "# 1. Initialize Hybrid Player (Now Player 2)\n",
    "try:\n",
    "    # Pass the correct player ID (PLAYER2_PIECE)\n",
    "    print(f\"\\nInitializing Hybrid Player ({HYBRID_PLAYER_ID}) with {HYBRID_ITERATIONS} iterations...\")\n",
    "    hybrid_player = MCTS_QAgent_Hybrid(\n",
    "        player_id=HYBRID_PLAYER_ID, # <-- Use the updated variable\n",
    "        q_table_path=Q_TABLE_TO_USE,\n",
    "        iterations=HYBRID_ITERATIONS\n",
    "    )\n",
    "    print(\"Hybrid Player initialized.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\nERROR: Required class not defined ({e}).\")\n",
    "    print(\"Ensure MCTS_QAgent_Hybrid, QLearningAgent, MCTSNode classes are defined.\")\n",
    "    players_ready = False\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Q-table file '{Q_TABLE_TO_USE}' not found for Hybrid Agent.\")\n",
    "    players_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred setting up the Hybrid Player: {e}\")\n",
    "    players_ready = False\n",
    "\n",
    "# 2. Initialize Human Player (Now Player 1)\n",
    "if players_ready:\n",
    "    try:\n",
    "        # Pass the correct player ID (PLAYER1_PIECE)\n",
    "        print(f\"\\nInitializing Human Player ({HUMAN_PLAYER_ID})...\")\n",
    "        human_player = HumanPlayer(player_id=HUMAN_PLAYER_ID) # <-- Use the updated variable\n",
    "        print(\"Human Player initialized.\")\n",
    "    except NameError:\n",
    "        print(\"\\nERROR: HumanPlayer class not defined.\")\n",
    "        print(\"Please ensure the cell containing the HumanPlayer class definition (e.g., Cell 2) has been executed.\")\n",
    "        players_ready = False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred setting up the Human Player: {e}\")\n",
    "        players_ready = False\n",
    "\n",
    "\n",
    "# --- Run Game ---\n",
    "if players_ready and hybrid_player and human_player:\n",
    "    try:\n",
    "        # Update the starting game message\n",
    "        print(\"\\nStarting game: Human (P1) vs Hybrid MCTS+QAgent (P2)\") # <-- UPDATED TITLE\n",
    "\n",
    "        if HYBRID_PLAYER_ID == PLAYER1_PIECE: \n",
    "            play_connect4(hybrid_player, human_player)\n",
    "        else: \n",
    "            play_connect4(human_player, hybrid_player)\n",
    "\n",
    "    except NameError:\n",
    "         print(\"\\nERROR: 'play_connect4' function not defined.\")\n",
    "         print(\"Please ensure the cell containing the play_connect4 function (e.g., Cell 6) has been executed.\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\nAn unexpected error occurred during the game: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nGame setup failed. Cannot start the match.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b4cd3-08b1-408c-b924-7ea1d1ff9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
